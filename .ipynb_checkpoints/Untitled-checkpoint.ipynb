{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style='text-align: right;'>ניתוח מסמכים באמצעות&#x202b; TF-IDF </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <p style='text-align: right;'>שיעור מאת: מת'יו ג'יי. לוין </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <p style='text-align: right;'>תורגם לעברית על ידי תמיר פרייפלד</p>\n",
    "<p style='text-align: right;'>&#x202b;השיעור תורגם בלשון נקבה, אך מיועד לכל המגדרים.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;שיעור זה מתמקד בשיטה עיקרית מתחומי עיבוד שפה טבעית ואחזור מידע הקרויה TF-IDF - Term Frequency - Inverse Document Frequency (תדירות מונח - תדירות מסמך הפכית). שיעור זה סוקר את היסודות של TF-IDF, וכמו כן יציג בפנייך חלק מהשאלות והרעיונות העולים בניתוח טקסטים מונחה חישוביות.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <p style='text-align: right;'>&#x202b;סקירה</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;שיעור זה מתמקד בשיטה יסודית מתחומי עיבוד שפה טבעית ואחזור מידע הקרויה TF-IDF - Term Frequency - Inverse Document Frequency (תדירות מונח - תדירות מסמך הפכית). ייתכן ושמעת על TF-IDF בהקשר למידול נושאים (Topic Modeling), למידת מכונה, או שיטות אחרות הנוגעות לניתוח טקטסים. TF-IDF מוזכר רבות בפרסומים בגלל שהוא מהווה גם שיטה לחקירת קורפוס וגם שלב עיבוד מקדים בהרבה מודלים נוספים לכריית טקסטים.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;התבוננות מקרוב על TF-IDF תשאיר אותך עם שיטה לניתוח טקטסים הניתנת ליישום מיידית. כמו כן, שיעור זה יציג בפנייך את חלק מן השאלות והרעיונות העולים בניתוח טקטסטים מונחה חישוביות. בפרט, שיעור זה מציג דרך בה תוכלי לזהות את המילים החשובות ביותר במסמך ולבודד אותן מסוג המילים הנוטות להופיע בתדירות גבוהה על פני אוסף של מסמכים באותה שפה. בנוסף ל-TF-IDF, ישנן מספר שיטות חישוביות לקביעת אילו מילים או ביטויים מאפיינים אוסף של מסמכים, ובהקשר זה, אני ממליץ מאוד על הפוסט של טד אנדרווד בבלוג שלו משנת 2011 להעמקה (1).</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <p style='text-align: right;'>&#x202b;הכנה</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style='text-align: right;'>&#x202b; כישורים קודמים מומלצים</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul dir=RTL><li><p style='text-align: right;'>&#x202b;הכרות קודמת עם פייתון או שפת תכנות דומה.\n",
    "    הקוד בשיעור זה כתוב בפייתון 3.6, אבל תוכלי להריץ את TF-IDF במגוון גרסאות שונות של פייתון, באמצעות שימוש בחבילות שונות, או בשלל שפות תכנות אחרות. קשה להעריך את הרמה המדוייקת המומלצת של הכרות או אוריינות בקוד, אבל סביר כי תעדיפי להרגיש בנוח עם הטיפוסים הבסיסיים והפעולות הבסיסיות. על מנת להפיק את המירב מן השיעור, מומלץ שתעברי על משהו כדוגמת <a href=\"https://www.codecademy.com/learn/learn-python\">הקורס המקוון \"מבוא לפייתון\"\n",
    "של Codeacademy</a> , או שתשלימי חלק <a href=\"https://programminghistorian.org/en/lessons/introduction-and-installation\">משיעורי המבוא לפייתון הזמינים ב- The Programming Historian</a>.</p></li></ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul dir=RTL><li><p style='text-align: right;'>&#x202b;כחלופה להמלצה הנ\"ל, מומלץ כי תחזרי על <a href=\"https://www.learnpython.org/\">הטיפוסים הבסיסיים בפייתון</a> (string-מחרוזת, integer-מספר שלם, float -מספר נקודה צפה, list-רשימה, tuple-טאפל, dictionary-מילון), עבודה עם משתנים, כתיבת לולאות בפייתון, ועבודה עם מחלקות/מופעי אובייקטים.</p></li></ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul dir=RTL><li><p style='text-align: right;'>&#x202b;ניסיון עם אקסל או יישום גליונות אלקטורניים שקול אחר אם ברצונך לבחון את קבצי הגיליונות המקושרים. תוכלי  גם להשתמש בספריית pandas בפייתון כדי להציג קבצי CSV.</p></li></ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style='text-align: right;'>&#x202b;לפני שמתחילים</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul dir=RTL><li><p style='text-align: right;'>&#x202b;התקיני את גרסת הפייתון 3 של אנקונדה. התקנת אנקונדה מכוסה בשיעור <a href=\"https://programminghistorian.org/en/lessons/text-mining-with-extracted-features\">כריית מידע בפייתון באמצעות קורא תכונות HTRC</a>. ההתקנה תתקין את פייתון 3.6 (או גרסה מאוחרת יותר), את ספרית Scikit-Learn (בה נשתמש בשביל TF-IDF), והתלויות הנחוצות על מנת להריץ <a href=\"https://jupyter.org/\">מחברות Jupyter</a>.</p></li></ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul dir=RTL><li><p style='text-align: right;'>&#x202b;ניתן להקתין את כל התלויות האלו ללא אנקונדה (או על ידי חלופה קלה יותר כמון מיניקונדה). למידע נוסף, קראי את הסעיף למטה שכותרתו \"חלופות לאנקונדה\".</p></li></ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style='text-align: right;'>&#x202b;מערך הנתונים של השיעור</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;TF-IDF, כמו הרבה פעולות חישוביות, ניתן להבנה בצורה הטובה ביותר על-ידי דוגמה. למטרה זו, הכנתי מערך נתונים של 366 <a href=\"https://en.wikipedia.org/wiki/Obituary\">מודעות \"לזכרם\"</a>\n",
    " היסטוריות מתוך ה-New York Times, שנלקחו מתוך <a href=\"https://archive.nytimes.com/www.nytimes.com/learning/general/onthisday/\">https://archive.nytimes.com/www.nytimes.com/learning/general/onthisday/</a>. בכל יום של השנה, ה-New York Times הציג מודעת \"לזכרו\" של מישהו שנולד באותו תאריך. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;קבצי השיעור, כולל מערך הנתונים הנ\"ל, ניתנים להורדה מ-<a href=\"https://programminghistorian.org/assets/tf-idf/lesson-files.zip\">lesson-files.zip</a>. מערך הנתונים קטן דיו כך שתוכלי לפתוח ולקרוא את חלק, אם לא כל, הקבצים. הנתונים  המקוריים זמינים גם בתקיית ה-'obituaries', כולל קבצי ה-'.html' שהורדו מאתר ה-\"On This Day\" מ-2011 ותקיית קבצי \".txt\" שמייצגים את גוף מודעות ה\"לזכרם\". קבצי טקסט אלו נוצרו באמצעות <a href=\"https://docs.python.org/3/library/intro.html\">ספריית פייתון</a>\n",
    "  בשם <a href=\"https://www.crummy.com/software/BeautifulSoup/\">BeautifulSoup</a>, שמכוסה בשיעור אחר של The Programming Historian (ראי את <a href=\"https://programminghistorian.org/en/lessons/intro-to-beautiful-soup\">מבוא ל-BeautifulSoup</a>).\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;קורפוס מודעות ה\"לזכרם\" הזה הוא אובייקט היסטורי בזכות עצמו. הוא מייצג, במידה מסויימת, כיצד השאלות על הכללה וייצוג עשויים להשפיע הן על ההחלטה לפרסם מודעת \"לזכרו\", והן על ההחלטה להבליט מודעת \"לזכרו\" מסויימת שנים רבות לאחר מכן. המשמעות של החלטות כאלו הודגשה עוד יותר בחודשים האחרונים על-ידי ה-New York Times בעצמו. במרץ 2018, העיתון החל לפרסם מודעות \"לזכרן\" עבור \"נשים שהתעלמו מהן\" (2). במילותיה של אמישה פדנני וג'סיקה בנט, \"(ההחלטה על מיהם אותם אנחנו בוחרים לזכור - ת.פ.) - וכיצד - באופן אינהרנטי כוללת שיפוט. להתבונן בדיעבד על ארכיבי מודעות ה'לזכרם' יכול, על כן, להוות שיעור מוחלט אודות כיצד החברה העריכה הישגים שונים ואת משיגיהם.\" בהתבוננות תחת עדשת המיקרוסקופ, מערך הנתונים הנ\"ל מהווה לא רק דגימה מייצגת של מודעות \"לזכרם\" היסטוריות, אלא למעשה תמונת מצב של את מי ה-New York Times החשיב כראוי להדגשה ב-2010-2011. את תבחיני שהרבה מן הדמויות ההיסטוריות ידועות לכל, מה שמעיד על מאמץ בתת-מודע להתבונן על ההיסטוריה של ה-New York Times ולבחון את מודעות ה\"לזכרם\" בהתבסס על קריטריונים מסויימים (3).</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style='text-align: right;'>&#x202b;הגדרת TF-IDF ורקע</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;השיטה הקרויה TF-IDF הופיעה לראשונה במאמר של קרן ספארק ג'ונס משנת 1972, תחת השם \"ספציפיות מונח\" (4) - על אף שלעיתים קרובות הקרדיט משוייך בטעות לאחרים. על כן, הרי זה הולם שמודעת \"לזכרה\" מסוג \"נשים שהתעלמו מהן\" פורסמה בינואר 2019 (5).</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;עם TF-IDF, במקום לייצג מונח במסמך על ידי תדירותו הגולמית (מספר ההופעות שלו) או על ידי תדירותו היחסית (מספר הופעות המונח מחולק באורך המסמך), כל מונח ממושקל על-ידי חילוק תדירות המונח במספר המסמכים בקורפוס המכילים את המונח. התוצאה העיקרית של סכימת המשקול הזאת באה לידי ביטוי בהמנעות מבעיה נפוצה העולה בניתוח טקטסים: המילים השכיחות ביותר במסמך הן לעיתים קרובות המילים השכיחות ביותר בכל המסמכים. לעומת זאת, מונחים המקבלים דירוג TF-IDF גבוה הם המונחים שתדירותם במסמך גבוהה <i>באופן ייחודי</i>, כאשר עורכים השוואה של המסמך הנדון למול מסמכים אחרים.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;אם ההסבר הנ\"ל אינו משכנע מספיק, אנלוגיה קצרה עשויה לעזור. דמייני שאת בחופשה למשך סוף שבוע בעיר חדשה, הקרויה IDF סיטי. את מנסה לבחור מסעדה לארוחת ערב, ותרצי לאזן בין שתי מטרות: ראשית, תרצי לאכול ארוחה טובה מאוד, ושנית, תרצי לבחור בסגנון אוכל שטוב ב-IDF סיטי באופן ייחודי - כלומר, את רוצה לאכול משהו שלא תוכלי להשיג ב\"כל מקום אחר\". את יכולה לקרוא ביקורות ברשת כל היום, וזה עשוי לספק את המטרה הראשונה שלך, אבל מה שאת צריכה על מנת לספק את המטרה השנייה, היא דרך כלשהי להבדיל בין אוכל טוב לבין אוכל טוב באופן ייחודי (או אולי אפילו אוכל טוב באופן ייחודי).</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;זה קל יחסית, לדעתי, לראות שאוכל במסעדה יכול להיות:</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;<ol dir=RTL>\n",
    "    <li>טוב וייחודי</li>\n",
    "    <li>טוב אך לא ייחודי</li>\n",
    "    <li>לא טוב, אך ייחודי</li>\n",
    "    <li>לא טוב ולא ייחודי</li>\n",
    "</ol></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;,תדירות מונחים יכולה להיות בעלת אותו מבנה. מונח יכול להיות:</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;<ol dir=RTL>\n",
    "    <li>בשימוש רב בשפה, ובשימוש רב במיוחד או דל במיוחד במסמך מסוים</li>\n",
    "    <li>בשימוש רב בשפה, ובשימוש טיפוסי במסמך מסוים</li>\n",
    "    <li>בשימוש דל בשפה, אך בשימוש רב במיוחד או דל במיוחד במסמך מסוים</li>\n",
    "    <li>בשימוש דל בשפה, ובשימוש טיפוסי במסמך מסוים</li>\n",
    "</ol></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;על מנת להבין כיצד מילים יכולות להיות בשימוש תדיר אך לא ייחודיות, או ייחודיות אך לא בשימוש תדיר, הבא נבחן דוגמה. הרשימה הבאה מציגה את עשרת המונחים השכיחים ביותר (ביחד עם מספר הופעותיהם) מתוך אחת ממודעות ה\"לזכרם\" בקורפוס שלנו.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"width:100%\" >\n",
    "  <thead>\n",
    "  <tr>\n",
    "    <th>Rank</th>\n",
    "    <th>Term</th>\n",
    "    <th>Count</th>\n",
    "  </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "  <tr>\n",
    "    <td>1</td>\n",
    "    <td>the</td>\n",
    "    <td>21</td>\n",
    "  </tr>\n",
    "     <tr>\n",
    "    <td>2</td>\n",
    "    <td>of</td>\n",
    "    <td>16</td>\n",
    "  </tr>\n",
    "     <tr>\n",
    "    <td>3</td>\n",
    "    <td>her</td>\n",
    "    <td>15</td>\n",
    "  </tr>\n",
    "     <tr>\n",
    "    <td>4</td>\n",
    "    <td>in</td>\n",
    "    <td>14</td>\n",
    "  </tr>\n",
    "     <tr>\n",
    "    <td>5</td>\n",
    "    <td>and</td>\n",
    "    <td>13</td>\n",
    "  </tr>\n",
    "     <tr>\n",
    "    <td>6</td>\n",
    "    <td>she</td>\n",
    "    <td>10</td>\n",
    "  </tr>\n",
    "     <tr>\n",
    "    <td>7</td>\n",
    "    <td>at</td>\n",
    "    <td>8</td>\n",
    "  </tr>\n",
    "     <tr>\n",
    "    <td>8</td>\n",
    "    <td>cochrane</td>\n",
    "    <td>4</td>\n",
    "  </tr>\n",
    "     <tr>\n",
    "    <td>9</td>\n",
    "    <td>was</td>\n",
    "    <td>4</td>\n",
    "  </tr>\n",
    "     <tr>\n",
    "    <td>10</td>\n",
    "    <td>to</td>\n",
    "    <td>4</td>\n",
    "  </tr>\n",
    "    </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;לאחר התבוננות ברשימה, נסי לגזור מידה על מודעת ה\"לזכרה\" שהטבלה מייצגת. מהופעתן של המילים \"her\" ו-\"cochrane\" ברשימה אנו עשויים להסיק כי המודעה עוסקת  באישה בשם Cochrane, אך באותה מידה, המודעה עשויה לעסוק באדם שהגיע מ-Cochrane שבמדינת וויסקונסין, או במישהו שמקושר ל-<a href=\"https://en.wikipedia.org/wiki/Cochrane_(organisation)\">The Cochrane Collaboration</a>\n",
    ", ארגון א-ממשלתי ללא מטרות רווח. הבעיה עם הרשימה הזו, היא שמרבית המילים המופיעות בה יהוו את המילים השכיחות ביותר בכל מודעה - או בכלל בכל טקסט גדול מספיק ברוב השפות - ולאו דווקא השכיחות במודעה זו בלבד . זאת, היות ומרבית השפות תלויות במילים פונקציונליות כמו the, as, of, to ו-from, שמשמשות בעיקר לצרכים תחביריים או מבניים, ומופיעות ללא תלות בנושא הטקסט. רשימה של המונחים התדירים ביותר במודעת \"לזכרם\" מגלה לנו מעט מאוד על המודעה או על האדם אותו מנציחים בה. כעת, הבא נשתמש במשקול מונחים לפי TF-IDF על-מנת להשוות בין המודעה מהדוגמה הקודמת לבין שאר קורפוס המודעות שלנו. עשרת המונחים בעלי הדירוג הגבוה ביותר הינם: </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"width:100%\" >\n",
    "  <thead>\n",
    "  <tr>\n",
    "    <th>Rank</th>\n",
    "    <th>Term</th>\n",
    "    <th>Count</th>\n",
    "  </tr>\n",
    "      </thead>\n",
    "   <tbody>\n",
    "  <tr>\n",
    "    <td>1</td>\n",
    "    <td>cochrane</td>\n",
    "    <td>24.85</td>\n",
    "  </tr>\n",
    "     <tr>\n",
    "    <td>2</td>\n",
    "    <td>her</td>\n",
    "    <td>22.74</td>\n",
    "  </tr>\n",
    "     <tr>\n",
    "    <td>3</td>\n",
    "    <td>she</td>\n",
    "    <td>16.22</td>\n",
    "  </tr>\n",
    "     <tr>\n",
    "    <td>4</td>\n",
    "    <td>seaman</td>\n",
    "    <td>14.88</td>\n",
    "  </tr>\n",
    "     <tr>\n",
    "    <td>5</td>\n",
    "    <td>bly</td>\n",
    "    <td>12.42</td>\n",
    "  </tr>\n",
    "     <tr>\n",
    "    <td>6</td>\n",
    "    <td>nellie</td>\n",
    "    <td>9.92</td>\n",
    "  </tr>\n",
    "     <tr>\n",
    "    <td>7</td>\n",
    "    <td>mark</td>\n",
    "    <td>8.64</td>\n",
    "  </tr>\n",
    "     <tr>\n",
    "    <td>8</td>\n",
    "    <td>ironclad</td>\n",
    "    <td>6.21</td>\n",
    "  </tr>\n",
    "     <tr>\n",
    "    <td>9</td>\n",
    "    <td>plume</td>\n",
    "    <td>6.21</td>\n",
    "  </tr>\n",
    "     <tr>\n",
    "    <td>10</td>\n",
    "    <td>vexations</td>\n",
    "    <td>6.21</td>\n",
    "  </tr>\n",
    "       </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;בגרסה זו של הרשימה, she ו-her מדורגות גבוה יותר מאשר ברשימה הקודמת. cochrane נשארה ברשימה, אבל כעת יש לנו שתי מילים דמויות-שם חדשות: nellie ו-bly. <a href=\"https://he.wikipedia.org/wiki/%D7%A0%D7%9C%D7%99_%D7%91%D7%9C%D7%99%D7%99\">נלי בליי</a> הייתה  עיתונאית מסוף המאה ה-19 - תחילת המאה ה-20 הידועה בעיקר כיום בשל פועלה כעיתונאית חוקרת, ובמיוחד לאור זאת שהיא אשפזה את עצמה בבית משוגעים בעיר ניו-יורק למשך עשרה ימים על מנת לכתוב תחקיר על היחס הרע שמקבלים חולי הנפש המאושפזים שם. היא נולדה כאליזבת' ג'יין קוקריין, ובליי היה שם העט שלה (Nom-de-plume). עם מעט מאוד פרטים לגבי בליי, אנו יכולים לתת הסבר להופעתם של שבעה מתוך עשרת המונחים בטלבת ה-TF-IDF הנ\"ל: cochrane, her, she, seaman, bly, nellie ו-plume. על מנת לתת הסבר להופעתם של mark, ironclad ו-vexations, אנו יכולים לחזור למודעה ולגלות שבליי מתה בבית חולים סיינט מארק. <a href=\"https://en.wikipedia.org/wiki/Robert_Seaman\">בעלה</a> היה נשיא חברת \"איירונקלד ייצור\". לסיום, \"סדרה של זיופים על-ידי העובדים שלה, מחלוקות משלל סוגים, פשיטת רגל, שלל צרות (במקור vexations - ת.פ.) ודיונים משפטיים יקרים עלו לבליי את כל הונה\" (6). רבים מהמונחים ברשימה הזו מוזכרים פעם, פעמיים או שלוש - הם אינם תדירים בשום מובן. אמנם, הנוכחות שלהם ייחודית במסמך הזה ביחס לשאר המודעות בקורפוס. \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <p style='text-align: right;'>&#x202b;השיטה</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style='text-align: right;'>&#x202b;כיצד עובד האלגוריתם</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;ניתן לממש את TF-IDF במגוון דרכים, חלקן יותר מורכבות מהאחרות. לפני שאתחיל לדבר על המורכבויות האלו, ארצה לעקוב אחר הפעולות האלגוריתמיות של גרסה אחת מסוימת. לצורך זה, נחזור למודעת ה\"לזכרה\" של נלי בליי ונמיר את ספירות עשר המילים הנפוצות ביותר לדירוגי TF-IDF על-ידי שימוש באותם הצעדים שבוצעו על-מנת לייצר את דוגמת ה-TF-IDF הנ\"ל. השלבים האלה מקבילים לאלו שבמימוש ה-TF-IDF של ספריית <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">Scikit-Learn</a>. חיבור, כפל וחילוק הן הפעולות המתמטיות העיקריות הנחוצות. במהלך הדרך, אנו צריכים לחשב את <a href=\"https://he.wikipedia.org/wiki/%D7%9C%D7%95%D7%92%D7%A8%D7%99%D7%AA%D7%9D_%D7%98%D7%91%D7%A2%D7%99\">הלוגריתם הטבעי</a> של משתנה, אבל זה ניתן לביצוע על-ידי מרבית המחשבונים הזמינים ברשת ובטלפונים החכמים. למטה מופיעה טבלה עם הספירות הגולמיות של 30 המונחים הראשונים, בספר אלפבתי, מתוך המודעה של בליי, אבל בטבלה זו יש עמודה שנייה שמייצגת את מספר המסמכים בהם כל מונח מופיע. תדירות מסמך (df - document frequency) מונה את מספר המסמכים מהקורפוס בהם כל מילה מופיעה. תדירות מסמך למילה מסוימת ניתנת לייצוג על-ידי:</p> $df_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"width:100%\">\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>Index</th>\n",
    "      <th>Term</th>\n",
    "      <th>Count</th>\n",
    "      <th>Df</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>1</td>\n",
    "      <td>afternoon</td>\n",
    "      <td>1</td>\n",
    "      <td>66</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>2</td>\n",
    "      <td>against</td>\n",
    "      <td>1</td>\n",
    "      <td>189</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>3</td>\n",
    "      <td>age</td>\n",
    "      <td>1</td>\n",
    "      <td>224</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>4</td>\n",
    "      <td>ago</td>\n",
    "      <td>1</td>\n",
    "      <td>161</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>5</td>\n",
    "      <td>air</td>\n",
    "      <td>1</td>\n",
    "      <td>80</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>6</td>\n",
    "      <td>all</td>\n",
    "      <td>1</td>\n",
    "      <td>310</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>7</td>\n",
    "      <td>american</td>\n",
    "      <td>1</td>\n",
    "      <td>277</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>8</td>\n",
    "      <td>an</td>\n",
    "      <td>1</td>\n",
    "      <td>352</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>9</td>\n",
    "      <td>and</td>\n",
    "      <td>13</td>\n",
    "      <td>364</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>10</td>\n",
    "      <td>around</td>\n",
    "      <td>2</td>\n",
    "      <td>149</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>11</td>\n",
    "      <td>as</td>\n",
    "      <td>2</td>\n",
    "      <td>357</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>12</td>\n",
    "      <td>ascension</td>\n",
    "      <td>1</td>\n",
    "      <td>6</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>13</td>\n",
    "      <td>asylum</td>\n",
    "      <td>1</td>\n",
    "      <td>2</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>14</td>\n",
    "      <td>at</td>\n",
    "      <td>8</td>\n",
    "      <td>362</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>15</td>\n",
    "      <td>avenue</td>\n",
    "      <td>2</td>\n",
    "      <td>68</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>16</td>\n",
    "      <td>balloon</td>\n",
    "      <td>1</td>\n",
    "      <td>2</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>17</td>\n",
    "      <td>bankruptcy</td>\n",
    "      <td>1</td>\n",
    "      <td>8</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>18</td>\n",
    "      <td>barrel</td>\n",
    "      <td>1</td>\n",
    "      <td>7</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>19</td>\n",
    "      <td>baxter</td>\n",
    "      <td>1</td>\n",
    "      <td>4</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>20</td>\n",
    "      <td>be</td>\n",
    "      <td>1</td>\n",
    "      <td>332</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>21</td>\n",
    "      <td>beat</td>\n",
    "      <td>1</td>\n",
    "      <td>33</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>22</td>\n",
    "      <td>began</td>\n",
    "      <td>1</td>\n",
    "      <td>241</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>23</td>\n",
    "      <td>bell</td>\n",
    "      <td>1</td>\n",
    "      <td>24</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>24</td>\n",
    "      <td>bly</td>\n",
    "      <td>2</td>\n",
    "      <td>1</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>25</td>\n",
    "      <td>body</td>\n",
    "      <td>1</td>\n",
    "      <td>112</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>26</td>\n",
    "      <td>born</td>\n",
    "      <td>1</td>\n",
    "      <td>342</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>27</td>\n",
    "      <td>but</td>\n",
    "      <td>1</td>\n",
    "      <td>343</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>28</td>\n",
    "      <td>by</td>\n",
    "      <td>3</td>\n",
    "      <td>349</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>29</td>\n",
    "      <td>career</td>\n",
    "      <td>1</td>\n",
    "      <td>223</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>30</td>\n",
    "      <td>character</td>\n",
    "      <td>1</td>\n",
    "      <td>89</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;על מנת לחשב את תדירות המסמך ההפכית לכל מילה, הנוסחה המיידית תהיה $\\frac{N}{df_i}$ כאשר $N$ מייצג את מספר המסמכים הכולל בקורפוס. עם זאת, מימושים רבים מנרמלים את התוצאות עם פעולות נוספות. ב-TF-IDF, נרמול משמש לשתי מטרות: ראשית, למנוע הטיה בתדירות המילה ביחס למילים במסמכים קצרים או ארוכים יותר; שנית, על-מנת לחשב את ערך ה-IDF (תדירות מסמך הפכית) לכל מילה. לדוגמה, במימוש של Scikit-Learn משתמשים ב-$N+1$ במקום $N$, מחשבים את הלוגריתם הטבעי של $\\frac{(N+1)}{df_i}$ ואז מוסיפים $1$ לתוצאה הסופית. נחזור בהמשך השיעור לנושא של נרמול בסעיף בהמשך הקרוי \"הגדרות Scikit-Learn\".</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;על-מנת לבטא את טנרספורמציית ה-TF-IDF של Scikit-Learn (7), ניתן להשתמש במשוואה הבאה: </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$idf_i = \\ln [\\frac{N+1}{df_i}] +1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;ברגע שחשבנו את $idf_i$, נוכל לחשב את tf-idf<sub>i</sub> על-ידי הכפלה של $tf_i$ ב-$idf_i$:</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$tf\\mbox{-}idf_i = tf_i \\times idf_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;משוואות מתמטיות כמו אלו עלולות להיות מעט מבלבלות אם אינך רגילה להן. לאחר קצת ניסיון איתן, הן יכולות לספק תיאור מובן לפעולות אלגוריתם יותר טוב מכל הסבר כתוב. (לקריאה נוספת על הנושא, אני ממליץ להתחיל מ-\"Do Digital Humanists Need to Understand Algorithms?\" (8) של בן שמידט). על-מנת להפוך את משוואות ה-idf ו-tf-idf לברורות יותר, הוספתי שתי עמודות חדשות לטבלת תדירות המילים ממקודם. העמודה החדשה הראשונה מייצגת את דירוג ה-idf הנגזר, והעמודה החדשה השנייה מכפילה את עמודת ה-Count בעמודת ה-Idf החדשה על-מנת לגזור את דירוג ה-tf-idf הסופי. הבחיני כי דירוג ה-idf גבוה יותר אם המילה מופיעה בפחות מסמכים, אך שטווח דירוגי ה-idf שאנו רואים הוא בין 1 ל-6. שיטות <a href=\"https://en.wikipedia.org/wiki/Normalization_(statistics)\">נרמול</a> שונות יגררו טווחים שונים.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;כמו כן, שימי לב כי ערכי עמודת ה-tf-idf, לפי גרסה זו של האלגוריתם, לא יכולים להיות נמוכים יותר מאלו שבעמודת ה-count. תוצאה זו היא גם תולדה של שיטת הנרמול שלנו; הוספת $1$ לערכי ה-idf הסופיים מבטיחה שלעולם לא נכפול את ערכי עמודת ה-count במספר קטן מ-$1$, מה שמשמר את ההתפלגות המקורית של הנתונים.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<table style=\"width:100%\">\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>Index</th>\n",
    "      <th>Term</th>\n",
    "      <th>Count</th>\n",
    "      <th>Df</th>\n",
    "      <th>Idf</th>\n",
    "      <th>Tf-idf</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>1</td>\n",
    "      <td>afternoon</td>\n",
    "      <td>1</td>\n",
    "      <td>66</td>\n",
    "      <td>2.70066923</td>\n",
    "      <td>2.70066923</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>2</td>\n",
    "      <td>against</td>\n",
    "      <td>1</td>\n",
    "      <td>189</td>\n",
    "      <td>1.65833778</td>\n",
    "      <td>1.65833778</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>3</td>\n",
    "      <td>age</td>\n",
    "      <td>1</td>\n",
    "      <td>224</td>\n",
    "      <td>1.48926145</td>\n",
    "      <td>1.48926145</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>4</td>\n",
    "      <td>ago</td>\n",
    "      <td>1</td>\n",
    "      <td>161</td>\n",
    "      <td>1.81776551</td>\n",
    "      <td>1.81776551</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>5</td>\n",
    "      <td>air</td>\n",
    "      <td>1</td>\n",
    "      <td>80</td>\n",
    "      <td>2.51091269</td>\n",
    "      <td>2.51091269</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>6</td>\n",
    "      <td>all</td>\n",
    "      <td>1</td>\n",
    "      <td>310</td>\n",
    "      <td>1.16556894</td>\n",
    "      <td>1.16556894</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>7</td>\n",
    "      <td>american</td>\n",
    "      <td>1</td>\n",
    "      <td>277</td>\n",
    "      <td>1.27774073</td>\n",
    "      <td>1.27774073</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>8</td>\n",
    "      <td>an</td>\n",
    "      <td>1</td>\n",
    "      <td>352</td>\n",
    "      <td>1.03889379</td>\n",
    "      <td>1.03889379</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>9</td>\n",
    "      <td>and</td>\n",
    "      <td>13</td>\n",
    "      <td>364</td>\n",
    "      <td>1.00546449</td>\n",
    "      <td>13.07103843</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>10</td>\n",
    "      <td>around</td>\n",
    "      <td>2</td>\n",
    "      <td>149</td>\n",
    "      <td>1.89472655</td>\n",
    "      <td>3.78945311</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>11</td>\n",
    "      <td>as</td>\n",
    "      <td>2</td>\n",
    "      <td>357</td>\n",
    "      <td>1.02482886</td>\n",
    "      <td>2.04965772</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>12</td>\n",
    "      <td>ascension</td>\n",
    "      <td>1</td>\n",
    "      <td>6</td>\n",
    "      <td>4.95945170</td>\n",
    "      <td>4.95945170</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>13</td>\n",
    "      <td>asylum</td>\n",
    "      <td>1</td>\n",
    "      <td>2</td>\n",
    "      <td>5.80674956</td>\n",
    "      <td>5.80674956</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>14</td>\n",
    "      <td>at</td>\n",
    "      <td>8</td>\n",
    "      <td>362</td>\n",
    "      <td>1.01095901</td>\n",
    "      <td>8.08767211</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>15</td>\n",
    "      <td>avenue</td>\n",
    "      <td>2</td>\n",
    "      <td>68</td>\n",
    "      <td>2.67125534</td>\n",
    "      <td>5.34251069</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>16</td>\n",
    "      <td>balloon</td>\n",
    "      <td>1</td>\n",
    "      <td>2</td>\n",
    "      <td>5.80674956</td>\n",
    "      <td>5.80674956</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>17</td>\n",
    "      <td>bankruptcy</td>\n",
    "      <td>1</td>\n",
    "      <td>8</td>\n",
    "      <td>4.70813727</td>\n",
    "      <td>4.70813727</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>18</td>\n",
    "      <td>barrel</td>\n",
    "      <td>1</td>\n",
    "      <td>7</td>\n",
    "      <td>4.82592031</td>\n",
    "      <td>4.82592031</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>19</td>\n",
    "      <td>baxter</td>\n",
    "      <td>1</td>\n",
    "      <td>4</td>\n",
    "      <td>5.29592394</td>\n",
    "      <td>5.29592394</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>20</td>\n",
    "      <td>be</td>\n",
    "      <td>1</td>\n",
    "      <td>332</td>\n",
    "      <td>1.09721936</td>\n",
    "      <td>1.09721936</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>21</td>\n",
    "      <td>beat</td>\n",
    "      <td>1</td>\n",
    "      <td>33</td>\n",
    "      <td>3.37900132</td>\n",
    "      <td>3.37900132</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>22</td>\n",
    "      <td>began</td>\n",
    "      <td>1</td>\n",
    "      <td>241</td>\n",
    "      <td>1.41642412</td>\n",
    "      <td>1.41642412</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>23</td>\n",
    "      <td>bell</td>\n",
    "      <td>1</td>\n",
    "      <td>24</td>\n",
    "      <td>3.68648602</td>\n",
    "      <td>3.68648602</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>24</td>\n",
    "      <td>bly</td>\n",
    "      <td>2</td>\n",
    "      <td>1</td>\n",
    "      <td>6.21221467</td>\n",
    "      <td>12.42442933</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>25</td>\n",
    "      <td>body</td>\n",
    "      <td>1</td>\n",
    "      <td>112</td>\n",
    "      <td>2.17797403</td>\n",
    "      <td>2.17797403</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>26</td>\n",
    "      <td>born</td>\n",
    "      <td>1</td>\n",
    "      <td>342</td>\n",
    "      <td>1.06763140</td>\n",
    "      <td>1.06763140</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>27</td>\n",
    "      <td>but</td>\n",
    "      <td>1</td>\n",
    "      <td>343</td>\n",
    "      <td>1.06472019</td>\n",
    "      <td>1.06472019</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>28</td>\n",
    "      <td>by</td>\n",
    "      <td>3</td>\n",
    "      <td>349</td>\n",
    "      <td>1.04742869</td>\n",
    "      <td>3.14228608</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>29</td>\n",
    "      <td>career</td>\n",
    "      <td>1</td>\n",
    "      <td>223</td>\n",
    "      <td>1.49371580</td>\n",
    "      <td>1.49371580</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>30</td>\n",
    "      <td>character</td>\n",
    "      <td>1</td>\n",
    "      <td>89</td>\n",
    "      <td>2.40555218</td>\n",
    "      <td>2.40555218</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;טבלאות אלו מייצגות ביחד גרסה אחת מסויימת של טרנספורמציית ה-tf-idf. כמובן, tf-idf בדרך-כלל מחושבת עבור כל המילים על גבי כל המסמכים בקורפוס כך שאת יכולה לראות לאילו מילים בכל מסמך יש את דירוגי ה-tf-idf הגבוהים ביותר. על-מנת לקבל תחושה יותר טובה כיצד הפלט שלך עשוי להראות לאחר ביצוע פעולה כזו, הורידי ופתחי את קובץ האקסל המלא עבור מודעת ה\"לזכרה\" של בליי -  הורידי את <a href=\"https://programminghistorian.org/assets/tf-idf/lesson-files.zip\">קבצים אלו</a>, חלצי את ארכיב ה-\".zip\" ופתחי את הקובץ \"bly_tfidf_all.xlsx\".</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style='text-align: right;'>&#x202b;כיצד להריץ בפייתון 3</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;בחלק זה של השיעור, אעבור על הצעדים שהצגתי עבור חישוב ערכי ה-tf-idf, עבור כל המילים על פני כל המסמכים בקורפוס שלנו. אם תרצי לעקוב, תוכלי להוריד את קבצי השיעור, לחלץ את ארכיב ה-\".zip\", ולהריץ את מחברת ה-Jupyter בתוך תיקיית ה-\"lesson\". תוכלי גם ליצור מחברת Jupyter חדשה באותו מיקום, ולהעתיק/להדביק קטעי קוד מהשיעור הזה לאורך הדרך. אם את משתמשת באנקונדה, בקרי <a href=\"https://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/execute.html\">בעמוד התיעוד של מחברות Jupyter</a> למידע נוסף על שינוי מקום האתחול של מחברת Jupyter. כמו ברוב שפות התכנות, ישנה יותר מדרך אחת לעשות את כל  אחד מהשלבים בהם אדון למטה.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;בלוק הקוד הראשון שנראה תוכנן למצוא את כל שמות הקבצים עבור כל קבצי \".txt\" בתיקייה \"txt\". שורות הקוד הבאות מייבאות את מחלקת ה-<code>Path</code> מספריית <code>pathlib</code> ומשתמשות במתודה <bdo><code>Path().rglob()</code></bdo> על-מנת ליצור רשימה של כל הקבצים בתיקיית \"txt\" שמסתיימים עם \".txt\". הספרייה  <code>pathlib</code> גם תצרף את מיקום התקייה <code>file.parent</code> אל כל שם קובץ על-מנת לספק נתיבים מלאים לכל קובץ (הן ב-Windows והן ב-MacOS).</p>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;על-ידי שימוש בשיטה הנ\"ל, אני מחבר כל שם קובץ לרשימה הנקראת <code>all_txt_files</code>. לבסוף, אני מחזיר את האורך של <code>all_txt_files</code> על-מנת לוודא שמצאתי את כל 366 שמות הקבצים. גישת ה\"רוץ-בלולאה-וצרף\" הזו מאוד שכיחה בפייתון.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "366\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "all_txt_files =[]\n",
    "for file in Path(\"txt\").rglob(\"*.txt\"):\n",
    "     all_txt_files.append(file.parent / file.name)\n",
    "# counts the length of the list\n",
    "n_files = len(all_txt_files)\n",
    "print(n_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;הערה מהירה לגבי שמות משתנים. שתי שיטות <a href=\"https://he.wikipedia.org/wiki/%D7%A9%D7%99%D7%95%D7%9D\">שיום</a> המשתנים הנפוצות ביותר מתעדפות נוחות ומשמעות סמנטית בהתאמה. לנוחות, ניתן לקרוא למשתנה <code>x</code> וכך יהיה קל ומהר יותר להקליד את שמו כשנצטרך להתייחס אליו. שמות סמנטיים, לעומת זאת, מנסים לתאר פעולה או מטרה. על-ידי קריאה לרשימת כל קבצי הטקסט <code>all_txt_files</code> ולמשתנה שמייצג את מספר הקבצים <code>n_files</code>, אני מתעדף משמעות סמנטית. יחד עם זאת, אני משתמש בקיצורים כמו <code>txt</code> לטקסט ו-<code>n</code> למספר (number) כדי לחסוך בהקלדה, או משתמש ב-<code>all_txt_file</code> במקום ב-<code>all_txt_file_names</code> בגלל שקצרנות עדיין חשובה. נורמות של שימוש בקו תחתון ואותיות גדולות מוסברות ב-PEP-8, מדריך הסגנון הרשמי של פייתון. כדאי לך להכיר אותו (9).</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;משלל סיבות, אנו רוצים למיין את הקבצים שלנו לפי סדר מספרי עולה, היות ויש לנו קובץ עבור כל יום בחודש ועבור כל חודש בשנה. אנו יכולים להשתמש במתודה <bdo><code>sort()</code></bdo> על-מנת למיין את הקבצים בסדר מספרי עולה ולהדפיס את השם הקובץ הראשון על-מנת לוודא שהוא אכן הקובץ \"txt.0101.txt\". </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('txt/0101.txt')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_txt_files.sort()\n",
    "all_txt_files[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;כעת, אנו יכולים להשתמש ברשימת שמות הקבצים שלנו על-מנת לטעון כל קובץ ולהמיר אותם לפורמט שפייתון יכול לקרוא ולהבין כטקסט. בקטע הקוד הבא, אני משתמש בפעולת \"רוץ-בלולאה-וצרף\" נופסת. הפעם, הלולאה רצה על רשימת שמות הקבצים ופותחת כל קובץ. אני משתמש במתודת ה-<bdo><code>read()</code></bdo> של פייתון על-מנת להמיר כל קובץ טקסט למחרוזת <code>(str)</code>, שזו הדרך בה פייתון יודע לחשוב על הנתונים כטקסט. אני מצרף את כל המחרוזות, אחת אחת, לרשימה חדשה שנקראת <code>all_docs</code>. נקודה חשובה - אובייקטי המחרוזת ברשימה הזו מסודרים באותו סדר שבו מסודרים שמות הקבצים ברשימה <code>all_txt_files</code>.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_docs = []\n",
    "for txt_file in all_txt_files:\n",
    "    with open(txt_file) as f:\n",
    "        txt_file_as_string = f.read()\n",
    "    all_docs.append(txt_file_as_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;זוהי כל העבודה המקדימה לה אנו נדרשים. שלבי עיבוד טקסט כמו <a href=\"https://en.wikipedia.org/wiki/Lexical_analysis#Tokenization\">טוקניזציה</a> והסרת סימני פיסוק תתבצע באופן אוטומטי כשנשתמש במחלקה <code>TfidfVectorizer</code> של Scikit-Learn על-מנת להמיר מסמכים מתוך רשימה של מחרוזות לדירוגי tf-idf. ניתן גם לספק רשימה של מילות-עצירה (מילים בשימוש שכיח שאת רוצה להתעלם מהן). על-מנת לבצע טוקניזציה ולהסיר מילות-עצירה בשפות שאינן אנגלית, את צריכה לבצע עיבוד מקדים על הטקסט עם ספריית פייתון אחרת או לספק טוקנייזר (שמבצע טוקניזציה) מותאם (ספציפית לאותה שפה - ת.פ.) ורשימת מילות-עצירה מתאימה, כאשר תשתמשי ב-<code>TfidfVectorizer</code>. קטע הקוד הבא מייבא את <code>TfidfVectorizer</code> מספריית Scikit-Learn, שמגיעה מותקנת מראש באנקונדה. <code>TfidfVectorizer</code> היא מחלקה (שנכתבה באמצעות תכנות מונחה-עצמים), ולכן אני מאתחל אותה עם פרמטרים ספציפיים כמשתנה בשם <code>vectorizer</code>. (ארחיב על הגדרות אלו בסעיף בהמשך הקרוי \"הגדרות Scikit-Learn\"). אחר-כך, אני מריץ את המתודה <bdo><code>fit_transform()</code></bdo> של האובייקט על רשימת המחרוזות שלי (משתנה בשם <code>all_docs</code>). המשתנה <code>X</code> הוא הפלט של המתודה <bdo><code>fit_transoform()</code></bdo>.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the TfidfVectorizer from Scikit-Learn.\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=.65, min_df=1, stop_words=None, use_idf=True, norm=None)\n",
    "transformed_documents = vectorizer.fit_transform(all_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;מתודת ה-<bdo><code>fit_transform()</code></bdo> הנ\"ל ממירה את רשימת המחרוזות לאובייקט הקרוי <a href=\"https://he.wikipedia.org/wiki/%D7%9E%D7%98%D7%A8%D7%99%D7%A6%D7%94_%D7%93%D7%9C%D7%99%D7%9C%D7%94\">מטריצה דלילה</a>. במקרה הזה, המטריצה מייצגת את ערכי ה-tf-idf לכל הטקסטים. מטריצות דלילות חוסכות בזיכרון על-ידי אי-שמירה של אפסים, אבל אנו רוצים גישה לאלו, אז קטע הקוד הבא משתמש במתודת ה-<bdo><code>toarray()</code></bdo> על-מנת להמיר את המטריצות הדלילות ל-<a href=\"https://docs.scipy.org/doc/numpy/reference/generated/numpy.array.html\">מערך Numpy</a>. אנחנו יכולים להדפיס את האורך של המערך על-מנת לוודא שהוא באותו אורך כמו רשימת המסמכים שלנו.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "366"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_documents_as_array = transformed_documents.toarray()\n",
    "# use this line of code to verify that the numpy array represents the same number of documents that we have in the file list\n",
    "len(transformed_documents_as_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;מערך Numpy הוא אובייקט דמוי רשימה, אך לא בדיוק כמו רשימה, ואני יכול לכתוב מדריך שלם על ההבדלים, אבל ישנו רק היבט אחד של מערכי Numpy שאנו צריכים לדעת כרגע: הוא ממיר את הנתונים המאוחסנים ב-<code>transformed_documents</code> לפורמט בו מיוצג כל דירוג tf-idf עבור כל מילה בכל מסמך. מטריצות דלילות, לעומת זאת, לא כוללות דירוגים שערכם אפס.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;אנו רוצים שכל מילה תהיה מיוצגת כך שלכל מסמך יהיה את אותו מספר הערכים, אחד עבור כל מילה בקורפוס. כל איבר ב-<code>transformed_documents_as_array</code> הוא מערך בעצמו המייצג מסמך אחד מהקורפוס שלנו. כתוצאה מכך, יש לנו למעשה רשת בה כל שורה מייצגת מסמך וכל עמודה מייצגת מילה. דמייני טבלה אחת מגיליון אלקטרוני המייצגת כל מסמך, כמו הטבלאות למעלה, אבל ללא תוויות על העמודות או השורות.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;על-מנת למזג את הערכים עם התוויות שלהם, אנו צריכים שתי פיסות מידע: סדר המסמכים, והסדר בו דירוגי מילים רשומים. את הסדר של המסמכים קל לדעת, כי זהו אותו סדר של המשתנה <code>all_docs_list</code>. רשימת המילים המלאה שמורה במשתנה ה-<code>vectorizer</code> שלנו, והיא באותו סדר בו כל איבר שומר ערכים ב-<code>transformed_documents_as_array</code>. אנו יכולים להשתמש במתודת ה-<bdo><code>get_feature_names()</code></bdo> של המחלקה <code>TfidfVectorizer</code> על-מנת לקבל את הרשימה הזו, ואז כל שורת נתונים (המהווה את דירוגי ה-tf-idf של מסמך) ניתנת לאיחוד מחדש עם רשימת המילים. (לעוד פרטים על מסגרות נתונים של pandas, ראי את השיעור <a href=\"https://programminghistorian.org/en/lessons/visualizing-with-bokeh\">ויזואליזציה של נתונים עם Bokeh ועם Pandas</a>.)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# make the output folder if it doesn't already exist\n",
    "Path(\"./tf_idf_output\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# construct a list of output file paths using the previous list of text files the relative path for tf_idf_output\n",
    "output_filenames = [str(txt_file).replace(\".txt\", \".csv\").replace(\"txt/\", \"tf_idf_output/\") for txt_file in all_txt_files]\n",
    "\n",
    "# loop each item in transformed_documents_as_array, using enumerate to keep track of the current position\n",
    "for counter, doc in enumerate(transformed_documents_as_array):\n",
    "    # construct a dataframe\n",
    "    tf_idf_tuples = list(zip(vectorizer.get_feature_names(), doc))\n",
    "    one_doc_as_df = pd.DataFrame.from_records(tf_idf_tuples, columns=['term', 'score']).sort_values(by='score', ascending=False).reset_index(drop=True)\n",
    "\n",
    "    # output to a csv using the enumerated value for the filename\n",
    "    one_doc_as_df.to_csv(output_filenames[counter])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;לקטע הקוד הבא ישנם שלושה חלקים:</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;<ol dir=RTL>\n",
    "    <li>\n",
    "        לאחר שייבאנו את ספריית Pandas, הוא מחפש ספרייה בשם \"tf_idf_output\" ויוצר אותה אם אינה קיימת.\n",
    "    </li>\n",
    "    <li>\n",
    "        הוא לוקח את רשימת קבצי ה-\".txt\" מקטע קוד קודם שהראיתי, ומשתמשת בה כדי להרכיב נתיב לקובץ \".csv\" לכל קובץ \".txt\". משתנה ה-<code>output_filenames</code>, לדוגמה, ימיר את \"txt/0101.txt\" (הנתיב של קובץ ה\".txt\" הראשון) ל-\"tf_idf_output/0101.csv\" וכך הלאה והלאה עבור כל קובץ.\n",
    "    </li>\n",
    "    <li>\n",
    "     באמצעות שימוש בלולאה, הקוד ממזג כל וקטור של דיורגי tf-idf עם שמות התכונות מ-<code>vectorizer</code>, ממיר כל זוג (מיזוג של מילה/דירוג) למסגרת הנתונים של Pandas, ושומר כל מסגרת נתונים בקובץ ה-\".csv\" המתאים לה. \n",
    "    </li>\n",
    "</ol></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style='text-align: right;'>&#x202b;פירוש רשימות מילים: המלצות ואזהרות</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;אחרי שהרצת את קטעי הקוד הנ\"ל, תהיה לך תיקייה בשם \"tf_idf_output\" עם 366 קבצי \".csv\" בתוכה. כל קובץ מתאים למודעת \"לזכרו\" מסויימת בתיקייה \"txt\", וכל אחד מכיל רשימה של מילים עם ציוני tf-idf לאותו מסמך. כפי שראינו עם המודעה של נלי בליי, רשימות המילים הללו יכולות להיות מאוד אינדיקיטביות; אמנם, זה חשוב להבין שפרשנות-יתר של התוצאות שקיבלנו יכולה למעשה לשבש את ההבנה שלך לגבי הטקסט החבוי.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;בכלליות, מוטב להתחיל עם הרעיון שרשימות המילים האלו יועילו להעלאת היפותזות או שאלות מחקר. Tf-idf </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;כיצד להריץ בפייתון 3</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
