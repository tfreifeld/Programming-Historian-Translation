{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style='text-align: right;'>ניתוח מסמכים באמצעות&#x202b; TF-IDF </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <p style='text-align: right;'>שיעור מאת: מת'יו ג'יי. לוין </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <p style='text-align: right;'>תורגם לעברית על ידי תמיר פרייפלד</p>\n",
    "<p style='text-align: right;'>&#x202b;השיעור תורגם בלשון נקבה, אך מיועד לכל המגדרים.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;שיעור זה מתמקד בשיטה עיקרית מתחומי עיבוד שפה טבעית ואחזור מידע הקרויה TF-IDF - Term Frequency - Inverse Document Frequency (תדירות מונח - תדירות מסמך הפכית). שיעור זה סוקר את היסודות של TF-IDF, וכמו כן יציג בפנייך חלק מהשאלות והרעיונות העולים בניתוח טקסטים מונחה חישוביות.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <p style='text-align: right;'>&#x202b;סקירה</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;שיעור זה מתמקד בשיטה יסודית מתחומי עיבוד שפה טבעית ואחזור מידע הקרויה TF-IDF - Term Frequency - Inverse Document Frequency (תדירות מונח - תדירות מסמך הפכית). ייתכן ושמעת על TF-IDF בהקשר למידול נושאים (Topic Modeling), למידת מכונה, או שיטות אחרות הנוגעות לניתוח טקטסים. TF-IDF מוזכר רבות בפרסומים בגלל שהוא מהווה גם שיטה לחקירת קורפוס וגם שלב עיבוד מקדים בהרבה מודלים נוספים לכריית טקסטים.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;התבוננות מקרוב על TF-IDF תשאיר אותך עם שיטה לניתוח טקטסים הניתנת ליישום מיידית. כמו כן, שיעור זה יציג בפנייך את חלק מן השאלות והרעיונות העולים בניתוח טקטסטים מונחה חישוביות. בפרט, שיעור זה מציג דרך בה תוכלי לזהות את המילים החשובות ביותר במסמך ולבודד אותן מסוג המילים הנוטות להופיע בתדירות גבוהה על פני אוסף של מסמכים באותה שפה. בנוסף ל-TF-IDF, ישנן מספר שיטות חישוביות לקביעת אילו מילים או ביטויים מאפיינים אוסף של מסמכים, ובהקשר זה, אני ממליץ מאוד על הפוסט של טד אנדרווד בבלוג שלו משנת 2011 להעמקה (1).</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <p style='text-align: right;'>&#x202b;הכנה</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style='text-align: right;'>&#x202b; כישורים קודמים מומלצים</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul dir=RTL><li><p style='text-align: right;'>&#x202b;הכרות קודמת עם פייתון או שפת תכנות דומה.\n",
    "    הקוד בשיעור זה כתוב בפייתון 3.6, אבל תוכלי להריץ את TF-IDF במגוון גרסאות שונות של פייתון, באמצעות שימוש בחבילות שונות, או בשלל שפות תכנות אחרות. קשה להעריך את הרמה המדוייקת המומלצת של הכרות או אוריינות בקוד, אבל סביר כי תעדיפי להרגיש בנוח עם הטיפוסים הבסיסיים והפעולות הבסיסיות. על מנת להפיק את המירב מן השיעור, מומלץ שתעברי על משהו כדוגמת <a href=\"https://www.codecademy.com/learn/learn-python\">הקורס המקוון \"מבוא לפייתון\"\n",
    "של Codeacademy</a> , או שתשלימי חלק <a href=\"https://programminghistorian.org/en/lessons/introduction-and-installation\">משיעורי המבוא לפייתון הזמינים ב- The Programming Historian</a>.</p></li></ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul dir=RTL><li><p style='text-align: right;'>&#x202b;כחלופה להמלצה הנ\"ל, מומלץ כי תחזרי על <a href=\"https://www.learnpython.org/\">הטיפוסים הבסיסיים בפייתון</a> (string-מחרוזת, integer-מספר שלם, float -מספר נקודה צפה, list-רשימה, tuple-טאפל, dictionary-מילון), עבודה עם משתנים, כתיבת לולאות בפייתון, ועבודה עם מחלקות/מופעי אובייקטים.</p></li></ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul dir=RTL><li><p style='text-align: right;'>&#x202b;ניסיון עם אקסל או יישום גליונות אלקטורניים שקול אחר אם ברצונך לבחון את קבצי הגיליונות המקושרים. תוכלי  גם להשתמש בספריית pandas בפייתון כדי להציג קבצי CSV.</p></li></ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style='text-align: right;'>&#x202b;לפני שמתחילים</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul dir=RTL><li><p style='text-align: right;'>&#x202b;התקיני את גרסת הפייתון 3 של אנקונדה. התקנת אנקונדה מכוסה בשיעור <a href=\"https://programminghistorian.org/en/lessons/text-mining-with-extracted-features\">כריית מידע בפייתון באמצעות קורא מאפיינים  HTRC</a>. ההתקנה תתקין את פייתון 3.6 (או גרסה מאוחרת יותר), את ספרית Scikit-Learn (בה נשתמש בשביל TF-IDF), והתלויות הנחוצות על מנת להריץ <a href=\"https://jupyter.org/\">מחברות Jupyter</a>.</p></li></ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul dir=RTL><li><p style='text-align: right;'>&#x202b;ניתן להקתין את כל התלויות האלו ללא אנקונדה (או על ידי חלופה קלה יותר כמון מיניקונדה). למידע נוסף, קראי את הסעיף למטה שכותרתו \"חלופות לאנקונדה\".</p></li></ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style='text-align: right;'>&#x202b;מערך הנתונים של השיעור</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;TF-IDF, כמו הרבה פעולות חישוביות, ניתן להבנה בצורה הטובה ביותר על-ידי דוגמה. למטרה זו, הכנתי מערך נתונים של 366 <a href=\"https://en.wikipedia.org/wiki/Obituary\">מודעות \"לזכרם\"</a>\n",
    " היסטוריות מתוך ה-New York Times, שנלקחו מתוך <a href=\"https://archive.nytimes.com/www.nytimes.com/learning/general/onthisday/\">https://archive.nytimes.com/www.nytimes.com/learning/general/onthisday/</a>. בכל יום של השנה, ה-New York Times הציג מודעת \"לזכרו\" של מישהו שנולד באותו תאריך. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;קבצי השיעור, כולל מערך הנתונים הנ\"ל, ניתנים להורדה מ-<a href=\"https://programminghistorian.org/assets/tf-idf/lesson-files.zip\">lesson-files.zip</a>. מערך הנתונים קטן דיו כך שתוכלי לפתוח ולקרוא את חלק, אם לא כל, הקבצים. הנתונים  המקוריים זמינים גם בתקיית ה-'obituaries', כולל קבצי ה-'.html' שהורדו מאתר ה-\"On This Day\" מ-2011 ותקיית קבצי \".txt\" שמייצגים את גוף מודעות ה\"לזכרם\". קבצי טקסט אלו נוצרו באמצעות <a href=\"https://docs.python.org/3/library/intro.html\">ספריית פייתון</a>\n",
    "  בשם <a href=\"https://www.crummy.com/software/BeautifulSoup/\">BeautifulSoup</a>, שמכוסה בשיעור אחר של The Programming Historian (ראי את <a href=\"https://programminghistorian.org/en/lessons/intro-to-beautiful-soup\">מבוא ל-BeautifulSoup</a>).\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;קורפוס מודעות ה\"לזכרם\" הזה הוא אובייקט היסטורי בזכות עצמו. הוא מייצג, במידה מסויימת, כיצד השאלות על הכללה וייצוג עשויים להשפיע הן על ההחלטה לפרסם מודעת \"לזכרו\", והן על ההחלטה להבליט מודעת \"לזכרו\" מסויימת שנים רבות לאחר מכן. המשמעות של החלטות כאלו הודגשה עוד יותר בחודשים האחרונים על-ידי ה-New York Times בעצמו. במרץ 2018, העיתון החל לפרסם מודעות \"לזכרן\" עבור \"נשים שהתעלמו מהן\" (2). במילותיה של אמישה פדנני וג'סיקה בנט, \"(ההחלטה על מיהם אותם אנחנו בוחרים לזכור - ת.פ.) - וכיצד - באופן אינהרנטי כוללת שיפוט. להתבונן בדיעבד על ארכיבי מודעות ה'לזכרם' יכול, על כן, להוות שיעור מוחלט אודות כיצד החברה העריכה הישגים שונים ואת משיגיהם.\" בהתבוננות תחת עדשת המיקרוסקופ, מערך הנתונים הנ\"ל מהווה לא רק דגימה מייצגת של מודעות \"לזכרם\" היסטוריות, אלא למעשה תמונת מצב של את מי ה-New York Times החשיב כראוי להדגשה ב-2010-2011. את תבחיני שהרבה מן הדמויות ההיסטוריות ידועות לכל, מה שמעיד על מאמץ בתת-מודע להתבונן על ההיסטוריה של ה-New York Times ולבחון את מודעות ה\"לזכרם\" בהתבסס על קריטריונים מסויימים (3).</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style='text-align: right;'>&#x202b;הגדרת TF-IDF ורקע</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;השיטה הקרויה TF-IDF הופיעה לראשונה במאמר של קרן ספארק ג'ונס משנת 1972, תחת השם \"ספציפיות מונח\" (4) - על אף שלעיתים קרובות הקרדיט משוייך בטעות לאחרים. על כן, הרי זה הולם שמודעת \"לזכרה\" מסוג \"נשים שהתעלמו מהן\" פורסמה בינואר 2019 (5).</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;עם TF-IDF, במקום לייצג מונח במסמך על ידי תדירותו הגולמית (מספר ההופעות שלו) או על ידי תדירותו היחסית (מספר הופעות המונח מחולק באורך המסמך), כל מונח ממושקל על-ידי חילוק תדירות המונח במספר המסמכים בקורפוס המכילים את המונח. התוצאה העיקרית של סכמת המשקול הזאת באה לידי ביטוי בהמנעות מבעיה נפוצה העולה בניתוח טקטסים: המילים השכיחות ביותר במסמך הן לעיתים קרובות המילים השכיחות ביותר בכל המסמכים. לעומת זאת, מונחים המקבלים ציון TF-IDF גבוה הם המונחים שתדירותם במסמך גבוהה <i>באופן ייחודי</i>, כאשר עורכים השוואה של המסמך הנדון למול מסמכים אחרים.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;אם ההסבר הנ\"ל אינו משכנע מספיק, אנלוגיה קצרה עשויה לעזור. דמייני שאת בחופשה למשך סוף שבוע בעיר חדשה, הקרויה IDF סיטי. את מנסה לבחור מסעדה לארוחת ערב, ותרצי לאזן בין שתי מטרות: ראשית, תרצי לאכול ארוחה טובה מאוד, ושנית, תרצי לבחור בסגנון אוכל שטוב ב-IDF סיטי באופן ייחודי - כלומר, את רוצה לאכול משהו שלא תוכלי להשיג ב\"כל מקום אחר\". את יכולה לקרוא ביקורות ברשת כל היום, וזה עשוי לספק את המטרה הראשונה שלך, אבל מה שאת צריכה על מנת לספק את המטרה השנייה, היא דרך כלשהי להבדיל בין אוכל טוב לבין אוכל טוב באופן ייחודי (או אולי אפילו אוכל טוב באופן ייחודי).</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;זה קל יחסית, לדעתי, לראות שאוכל במסעדה יכול להיות:</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;<ol dir=RTL>\n",
    "    <li>טוב וייחודי</li>\n",
    "    <li>טוב אך לא ייחודי</li>\n",
    "    <li>לא טוב, אך ייחודי</li>\n",
    "    <li>לא טוב ולא ייחודי</li>\n",
    "</ol></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;,תדירות מונחים יכולה להיות בעלת אותו מבנה. מונח יכול להיות:</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;<ol dir=RTL>\n",
    "    <li>בשימוש רב בשפה, ובשימוש רב במיוחד או דל במיוחד במסמך מסוים</li>\n",
    "    <li>בשימוש רב בשפה, ובשימוש טיפוסי במסמך מסוים</li>\n",
    "    <li>בשימוש דל בשפה, אך בשימוש רב במיוחד או דל במיוחד במסמך מסוים</li>\n",
    "    <li>בשימוש דל בשפה, ובשימוש טיפוסי במסמך מסוים</li>\n",
    "</ol></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;על מנת להבין כיצד מילים יכולות להיות בשימוש תדיר אך לא ייחודיות, או ייחודיות אך לא בשימוש תדיר, הבא נבחן דוגמה. הרשימה הבאה מציגה את עשרת המונחים השכיחים ביותר (ביחד עם מספר הופעותיהם) מתוך אחת ממודעות ה\"לזכרם\" בקורפוס שלנו.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"width:100%\" >\n",
    "  <thead>\n",
    "  <tr>\n",
    "    <th>Rank</th>\n",
    "    <th>Term</th>\n",
    "    <th>Count</th>\n",
    "  </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "  <tr>\n",
    "    <td>1</td>\n",
    "    <td>the</td>\n",
    "    <td>21</td>\n",
    "  </tr>\n",
    "     <tr>\n",
    "    <td>2</td>\n",
    "    <td>of</td>\n",
    "    <td>16</td>\n",
    "  </tr>\n",
    "     <tr>\n",
    "    <td>3</td>\n",
    "    <td>her</td>\n",
    "    <td>15</td>\n",
    "  </tr>\n",
    "     <tr>\n",
    "    <td>4</td>\n",
    "    <td>in</td>\n",
    "    <td>14</td>\n",
    "  </tr>\n",
    "     <tr>\n",
    "    <td>5</td>\n",
    "    <td>and</td>\n",
    "    <td>13</td>\n",
    "  </tr>\n",
    "     <tr>\n",
    "    <td>6</td>\n",
    "    <td>she</td>\n",
    "    <td>10</td>\n",
    "  </tr>\n",
    "     <tr>\n",
    "    <td>7</td>\n",
    "    <td>at</td>\n",
    "    <td>8</td>\n",
    "  </tr>\n",
    "     <tr>\n",
    "    <td>8</td>\n",
    "    <td>cochrane</td>\n",
    "    <td>4</td>\n",
    "  </tr>\n",
    "     <tr>\n",
    "    <td>9</td>\n",
    "    <td>was</td>\n",
    "    <td>4</td>\n",
    "  </tr>\n",
    "     <tr>\n",
    "    <td>10</td>\n",
    "    <td>to</td>\n",
    "    <td>4</td>\n",
    "  </tr>\n",
    "    </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;לאחר התבוננות ברשימה, נסי לגזור מידה על מודעת ה\"לזכרה\" שהטבלה מייצגת. מהופעתן של המילים \"her\" ו-\"cochrane\" ברשימה אנו עשויים להסיק כי המודעה עוסקת  באישה בשם Cochrane, אך באותה מידה, המודעה עשויה לעסוק באדם שהגיע מ-Cochrane שבמדינת וויסקונסין, או במישהו שמקושר ל-<a href=\"https://en.wikipedia.org/wiki/Cochrane_(organisation)\">The Cochrane Collaboration</a>\n",
    ", ארגון א-ממשלתי ללא מטרות רווח. הבעיה עם הרשימה הזו, היא שמרבית המילים המופיעות בה יהוו את המילים השכיחות ביותר בכל מודעה - או בכלל בכל טקסט גדול מספיק ברוב השפות - ולאו דווקא השכיחות במודעה זו בלבד . זאת, היות ומרבית השפות תלויות ב\"מילות פונקציה\" כמו the, as, of, to ו-from, שמשמשות בעיקר לצרכים תחביריים או מבניים, ומופיעות ללא תלות בנושא הטקסט. רשימה של המונחים התדירים ביותר במודעת \"לזכרם\" מגלה לנו מעט מאוד על המודעה או על האדם אותו מנציחים בה. כעת, הבא נשתמש במשקול מונחים לפי TF-IDF על-מנת להשוות בין המודעה מהדוגמה הקודמת לבין שאר קורפוס המודעות שלנו. עשרת המונחים בעלי הדירוג הגבוה ביותר הינם: </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"width:100%\" >\n",
    "  <thead>\n",
    "  <tr>\n",
    "    <th>Rank</th>\n",
    "    <th>Term</th>\n",
    "    <th>Count</th>\n",
    "  </tr>\n",
    "      </thead>\n",
    "   <tbody>\n",
    "  <tr>\n",
    "    <td>1</td>\n",
    "    <td>cochrane</td>\n",
    "    <td>24.85</td>\n",
    "  </tr>\n",
    "     <tr>\n",
    "    <td>2</td>\n",
    "    <td>her</td>\n",
    "    <td>22.74</td>\n",
    "  </tr>\n",
    "     <tr>\n",
    "    <td>3</td>\n",
    "    <td>she</td>\n",
    "    <td>16.22</td>\n",
    "  </tr>\n",
    "     <tr>\n",
    "    <td>4</td>\n",
    "    <td>seaman</td>\n",
    "    <td>14.88</td>\n",
    "  </tr>\n",
    "     <tr>\n",
    "    <td>5</td>\n",
    "    <td>bly</td>\n",
    "    <td>12.42</td>\n",
    "  </tr>\n",
    "     <tr>\n",
    "    <td>6</td>\n",
    "    <td>nellie</td>\n",
    "    <td>9.92</td>\n",
    "  </tr>\n",
    "     <tr>\n",
    "    <td>7</td>\n",
    "    <td>mark</td>\n",
    "    <td>8.64</td>\n",
    "  </tr>\n",
    "     <tr>\n",
    "    <td>8</td>\n",
    "    <td>ironclad</td>\n",
    "    <td>6.21</td>\n",
    "  </tr>\n",
    "     <tr>\n",
    "    <td>9</td>\n",
    "    <td>plume</td>\n",
    "    <td>6.21</td>\n",
    "  </tr>\n",
    "     <tr>\n",
    "    <td>10</td>\n",
    "    <td>vexations</td>\n",
    "    <td>6.21</td>\n",
    "  </tr>\n",
    "       </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;בגרסה זו של הרשימה, she ו-her מדורגות גבוה יותר מאשר ברשימה הקודמת. cochrane נשארה ברשימה, אבל כעת יש לנו שתי מילים דמויות-שם חדשות: nellie ו-bly. <a href=\"https://he.wikipedia.org/wiki/%D7%A0%D7%9C%D7%99_%D7%91%D7%9C%D7%99%D7%99\">נלי בליי</a> הייתה  עיתונאית מסוף המאה ה-19 - תחילת המאה ה-20 הידועה בעיקר כיום בשל פועלה כעיתונאית חוקרת, ובמיוחד לאור זאת שהיא אשפזה את עצמה בבית משוגעים בעיר ניו-יורק למשך עשרה ימים על מנת לכתוב תחקיר על היחס הרע שמקבלים חולי הנפש המאושפזים שם. היא נולדה כאליזבת' ג'יין קוקריין, ובליי היה שם העט שלה (Nom-de-plume). עם מעט מאוד פרטים לגבי בליי, אנו יכולים לתת הסבר להופעתם של שבעה מתוך עשרת המונחים בטלבת ה-TF-IDF הנ\"ל: cochrane, her, she, seaman, bly, nellie ו-plume. על מנת לתת הסבר להופעתם של mark, ironclad ו-vexations, אנו יכולים לחזור למודעה ולגלות שבליי מתה בבית חולים סיינט מארק. <a href=\"https://en.wikipedia.org/wiki/Robert_Seaman\">בעלה</a> היה נשיא חברת \"איירונקלד ייצור\". לסיום, \"סדרה של זיופים על-ידי העובדים שלה, מחלוקות משלל סוגים, פשיטת רגל, שלל צרות (במקור vexations - ת.פ.) ודיונים משפטיים יקרים עלו לבליי את כל הונה\" (6). רבים מהמונחים ברשימה הזו מוזכרים פעם, פעמיים או שלוש - הם אינם תדירים בשום מובן. אמנם, הנוכחות שלהם ייחודית במסמך הזה ביחס לשאר המודעות בקורפוס. \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <p style='text-align: right;'>&#x202b;השיטה</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style='text-align: right;'>&#x202b;כיצד עובד האלגוריתם</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;ניתן לממש את TF-IDF במגוון דרכים, חלקן יותר מורכבות מהאחרות. לפני שאתחיל לדבר על המורכבויות האלו, ארצה לעקוב אחר הפעולות האלגוריתמיות של גרסה אחת מסוימת. לצורך זה, נחזור למודעת ה\"לזכרה\" של נלי בליי ונמיר את ספירות עשר המילים הנפוצות ביותר לציוני TF-IDF על-ידי שימוש באותם הצעדים שבוצעו על-מנת לייצר את דוגמת ה-TF-IDF הנ\"ל. השלבים האלה מקבילים לאלו שבמימוש ה-TF-IDF של ספריית <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">Scikit-Learn</a>. חיבור, כפל וחילוק הן הפעולות המתמטיות העיקריות הנחוצות. במהלך הדרך, אנו צריכים לחשב את <a href=\"https://he.wikipedia.org/wiki/%D7%9C%D7%95%D7%92%D7%A8%D7%99%D7%AA%D7%9D_%D7%98%D7%91%D7%A2%D7%99\">הלוגריתם הטבעי</a> של משתנה, אבל זה ניתן לביצוע על-ידי מרבית המחשבונים הזמינים ברשת ובטלפונים החכמים. למטה מופיעה טבלה עם הספירות הגולמיות של 30 המונחים הראשונים, בספר אלפבתי, מתוך המודעה של בליי, אבל בטבלה זו יש עמודה שנייה שמייצגת את מספר המסמכים בהם כל מונח מופיע. תדירות מסמך (df - document frequency) מונה את מספר המסמכים מהקורפוס בהם כל מילה מופיעה. תדירות מסמך למילה מסוימת ניתנת לייצוג על-ידי:</p> $df_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"width:100%\">\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>Index</th>\n",
    "      <th>Term</th>\n",
    "      <th>Count</th>\n",
    "      <th>Df</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>1</td>\n",
    "      <td>afternoon</td>\n",
    "      <td>1</td>\n",
    "      <td>66</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>2</td>\n",
    "      <td>against</td>\n",
    "      <td>1</td>\n",
    "      <td>189</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>3</td>\n",
    "      <td>age</td>\n",
    "      <td>1</td>\n",
    "      <td>224</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>4</td>\n",
    "      <td>ago</td>\n",
    "      <td>1</td>\n",
    "      <td>161</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>5</td>\n",
    "      <td>air</td>\n",
    "      <td>1</td>\n",
    "      <td>80</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>6</td>\n",
    "      <td>all</td>\n",
    "      <td>1</td>\n",
    "      <td>310</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>7</td>\n",
    "      <td>american</td>\n",
    "      <td>1</td>\n",
    "      <td>277</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>8</td>\n",
    "      <td>an</td>\n",
    "      <td>1</td>\n",
    "      <td>352</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>9</td>\n",
    "      <td>and</td>\n",
    "      <td>13</td>\n",
    "      <td>364</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>10</td>\n",
    "      <td>around</td>\n",
    "      <td>2</td>\n",
    "      <td>149</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>11</td>\n",
    "      <td>as</td>\n",
    "      <td>2</td>\n",
    "      <td>357</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>12</td>\n",
    "      <td>ascension</td>\n",
    "      <td>1</td>\n",
    "      <td>6</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>13</td>\n",
    "      <td>asylum</td>\n",
    "      <td>1</td>\n",
    "      <td>2</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>14</td>\n",
    "      <td>at</td>\n",
    "      <td>8</td>\n",
    "      <td>362</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>15</td>\n",
    "      <td>avenue</td>\n",
    "      <td>2</td>\n",
    "      <td>68</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>16</td>\n",
    "      <td>balloon</td>\n",
    "      <td>1</td>\n",
    "      <td>2</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>17</td>\n",
    "      <td>bankruptcy</td>\n",
    "      <td>1</td>\n",
    "      <td>8</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>18</td>\n",
    "      <td>barrel</td>\n",
    "      <td>1</td>\n",
    "      <td>7</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>19</td>\n",
    "      <td>baxter</td>\n",
    "      <td>1</td>\n",
    "      <td>4</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>20</td>\n",
    "      <td>be</td>\n",
    "      <td>1</td>\n",
    "      <td>332</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>21</td>\n",
    "      <td>beat</td>\n",
    "      <td>1</td>\n",
    "      <td>33</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>22</td>\n",
    "      <td>began</td>\n",
    "      <td>1</td>\n",
    "      <td>241</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>23</td>\n",
    "      <td>bell</td>\n",
    "      <td>1</td>\n",
    "      <td>24</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>24</td>\n",
    "      <td>bly</td>\n",
    "      <td>2</td>\n",
    "      <td>1</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>25</td>\n",
    "      <td>body</td>\n",
    "      <td>1</td>\n",
    "      <td>112</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>26</td>\n",
    "      <td>born</td>\n",
    "      <td>1</td>\n",
    "      <td>342</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>27</td>\n",
    "      <td>but</td>\n",
    "      <td>1</td>\n",
    "      <td>343</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>28</td>\n",
    "      <td>by</td>\n",
    "      <td>3</td>\n",
    "      <td>349</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>29</td>\n",
    "      <td>career</td>\n",
    "      <td>1</td>\n",
    "      <td>223</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>30</td>\n",
    "      <td>character</td>\n",
    "      <td>1</td>\n",
    "      <td>89</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;על מנת לחשב את תדירות המסמך ההפכית לכל מילה, הנוסחה המיידית תהיה $\\frac{N}{df_i}$ כאשר $N$ מייצג את מספר המסמכים הכולל בקורפוס. עם זאת, מימושים רבים מנרמלים את התוצאות עם פעולות נוספות. ב-TF-IDF, נרמול משמש לשתי מטרות: ראשית, למנוע הטיה בתדירות המילה ביחס למילים במסמכים קצרים או ארוכים יותר; שנית, על-מנת לחשב את ערך ה-IDF (תדירות מסמך הפכית) לכל מילה. לדוגמה, במימוש של Scikit-Learn משתמשים ב-$N+1$ במקום $N$, מחשבים את הלוגריתם הטבעי של $\\frac{(N+1)}{df_i}$ ואז מוסיפים $1$ לתוצאה הסופית. נחזור בהמשך השיעור לנושא של נרמול בסעיף בהמשך הקרוי \"הגדרות Scikit-Learn\".</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;על-מנת לבטא את טנרספורמציית ה-TF-IDF של Scikit-Learn (7), ניתן להשתמש במשוואה הבאה: </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$idf_i = \\ln [\\frac{N+1}{df_i}] +1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;ברגע שחשבנו את $idf_i$, נוכל לחשב את tf-idf<sub>i</sub> על-ידי הכפלה של $tf_i$ ב-$idf_i$:</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$tf\\mbox{-}idf_i = tf_i \\times idf_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;משוואות מתמטיות כמו אלו עלולות להיות מעט מבלבלות אם אינך רגילה להן. לאחר קצת ניסיון איתן, הן יכולות לספק תיאור מובן לפעולות אלגוריתם יותר טוב מכל הסבר כתוב. (לקריאה נוספת על הנושא, אני ממליץ להתחיל מ-\"Do Digital Humanists Need to Understand Algorithms?\" (8) של בן שמידט). על-מנת להפוך את משוואות ה-idf ו-tf-idf לברורות יותר, הוספתי שתי עמודות חדשות לטבלת תדירות המילים ממקודם. העמודה החדשה הראשונה מייצגת את ציון ה-idf הנגזר, והעמודה החדשה השנייה מכפילה את עמודת ה-Count בעמודת ה-Idf החדשה על-מנת לגזור את ציון ה-tf-idf הסופי. הבחיני כי ציון ה-idf גבוה יותר אם המילה מופיעה בפחות מסמכים, אך שטווח ציוני ה-idf שאנו רואים הוא בין 1 ל-6. שיטות <a href=\"https://en.wikipedia.org/wiki/Normalization_(statistics)\">נרמול</a> שונות יגררו טווחים שונים.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;כמו כן, שימי לב כי ערכי עמודת ה-tf-idf, לפי גרסה זו של האלגוריתם, לא יכולים להיות נמוכים יותר מאלו שבעמודת ה-count. תוצאה זו היא גם תולדה של שיטת הנרמול שלנו; הוספת $1$ לערכי ה-idf הסופיים מבטיחה שלעולם לא נכפול את ערכי עמודת ה-count במספר קטן מ-$1$, מה שמשמר את ההתפלגות המקורית של הנתונים.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<table style=\"width:100%\">\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>Index</th>\n",
    "      <th>Term</th>\n",
    "      <th>Count</th>\n",
    "      <th>Df</th>\n",
    "      <th>Idf</th>\n",
    "      <th>Tf-idf</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>1</td>\n",
    "      <td>afternoon</td>\n",
    "      <td>1</td>\n",
    "      <td>66</td>\n",
    "      <td>2.70066923</td>\n",
    "      <td>2.70066923</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>2</td>\n",
    "      <td>against</td>\n",
    "      <td>1</td>\n",
    "      <td>189</td>\n",
    "      <td>1.65833778</td>\n",
    "      <td>1.65833778</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>3</td>\n",
    "      <td>age</td>\n",
    "      <td>1</td>\n",
    "      <td>224</td>\n",
    "      <td>1.48926145</td>\n",
    "      <td>1.48926145</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>4</td>\n",
    "      <td>ago</td>\n",
    "      <td>1</td>\n",
    "      <td>161</td>\n",
    "      <td>1.81776551</td>\n",
    "      <td>1.81776551</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>5</td>\n",
    "      <td>air</td>\n",
    "      <td>1</td>\n",
    "      <td>80</td>\n",
    "      <td>2.51091269</td>\n",
    "      <td>2.51091269</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>6</td>\n",
    "      <td>all</td>\n",
    "      <td>1</td>\n",
    "      <td>310</td>\n",
    "      <td>1.16556894</td>\n",
    "      <td>1.16556894</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>7</td>\n",
    "      <td>american</td>\n",
    "      <td>1</td>\n",
    "      <td>277</td>\n",
    "      <td>1.27774073</td>\n",
    "      <td>1.27774073</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>8</td>\n",
    "      <td>an</td>\n",
    "      <td>1</td>\n",
    "      <td>352</td>\n",
    "      <td>1.03889379</td>\n",
    "      <td>1.03889379</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>9</td>\n",
    "      <td>and</td>\n",
    "      <td>13</td>\n",
    "      <td>364</td>\n",
    "      <td>1.00546449</td>\n",
    "      <td>13.07103843</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>10</td>\n",
    "      <td>around</td>\n",
    "      <td>2</td>\n",
    "      <td>149</td>\n",
    "      <td>1.89472655</td>\n",
    "      <td>3.78945311</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>11</td>\n",
    "      <td>as</td>\n",
    "      <td>2</td>\n",
    "      <td>357</td>\n",
    "      <td>1.02482886</td>\n",
    "      <td>2.04965772</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>12</td>\n",
    "      <td>ascension</td>\n",
    "      <td>1</td>\n",
    "      <td>6</td>\n",
    "      <td>4.95945170</td>\n",
    "      <td>4.95945170</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>13</td>\n",
    "      <td>asylum</td>\n",
    "      <td>1</td>\n",
    "      <td>2</td>\n",
    "      <td>5.80674956</td>\n",
    "      <td>5.80674956</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>14</td>\n",
    "      <td>at</td>\n",
    "      <td>8</td>\n",
    "      <td>362</td>\n",
    "      <td>1.01095901</td>\n",
    "      <td>8.08767211</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>15</td>\n",
    "      <td>avenue</td>\n",
    "      <td>2</td>\n",
    "      <td>68</td>\n",
    "      <td>2.67125534</td>\n",
    "      <td>5.34251069</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>16</td>\n",
    "      <td>balloon</td>\n",
    "      <td>1</td>\n",
    "      <td>2</td>\n",
    "      <td>5.80674956</td>\n",
    "      <td>5.80674956</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>17</td>\n",
    "      <td>bankruptcy</td>\n",
    "      <td>1</td>\n",
    "      <td>8</td>\n",
    "      <td>4.70813727</td>\n",
    "      <td>4.70813727</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>18</td>\n",
    "      <td>barrel</td>\n",
    "      <td>1</td>\n",
    "      <td>7</td>\n",
    "      <td>4.82592031</td>\n",
    "      <td>4.82592031</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>19</td>\n",
    "      <td>baxter</td>\n",
    "      <td>1</td>\n",
    "      <td>4</td>\n",
    "      <td>5.29592394</td>\n",
    "      <td>5.29592394</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>20</td>\n",
    "      <td>be</td>\n",
    "      <td>1</td>\n",
    "      <td>332</td>\n",
    "      <td>1.09721936</td>\n",
    "      <td>1.09721936</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>21</td>\n",
    "      <td>beat</td>\n",
    "      <td>1</td>\n",
    "      <td>33</td>\n",
    "      <td>3.37900132</td>\n",
    "      <td>3.37900132</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>22</td>\n",
    "      <td>began</td>\n",
    "      <td>1</td>\n",
    "      <td>241</td>\n",
    "      <td>1.41642412</td>\n",
    "      <td>1.41642412</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>23</td>\n",
    "      <td>bell</td>\n",
    "      <td>1</td>\n",
    "      <td>24</td>\n",
    "      <td>3.68648602</td>\n",
    "      <td>3.68648602</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>24</td>\n",
    "      <td>bly</td>\n",
    "      <td>2</td>\n",
    "      <td>1</td>\n",
    "      <td>6.21221467</td>\n",
    "      <td>12.42442933</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>25</td>\n",
    "      <td>body</td>\n",
    "      <td>1</td>\n",
    "      <td>112</td>\n",
    "      <td>2.17797403</td>\n",
    "      <td>2.17797403</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>26</td>\n",
    "      <td>born</td>\n",
    "      <td>1</td>\n",
    "      <td>342</td>\n",
    "      <td>1.06763140</td>\n",
    "      <td>1.06763140</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>27</td>\n",
    "      <td>but</td>\n",
    "      <td>1</td>\n",
    "      <td>343</td>\n",
    "      <td>1.06472019</td>\n",
    "      <td>1.06472019</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>28</td>\n",
    "      <td>by</td>\n",
    "      <td>3</td>\n",
    "      <td>349</td>\n",
    "      <td>1.04742869</td>\n",
    "      <td>3.14228608</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>29</td>\n",
    "      <td>career</td>\n",
    "      <td>1</td>\n",
    "      <td>223</td>\n",
    "      <td>1.49371580</td>\n",
    "      <td>1.49371580</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>30</td>\n",
    "      <td>character</td>\n",
    "      <td>1</td>\n",
    "      <td>89</td>\n",
    "      <td>2.40555218</td>\n",
    "      <td>2.40555218</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;טבלאות אלו מייצגות ביחד גרסה אחת מסויימת של טרנספורמציית ה-tf-idf. כמובן, tf-idf בדרך-כלל מחושבת עבור כל המילים על גבי כל המסמכים בקורפוס כך שאת יכולה לראות לאילו מילים בכל מסמך יש את ציוני ה-tf-idf הגבוהים ביותר. על-מנת לקבל תחושה יותר טובה כיצד הפלט שלך עשוי להראות לאחר ביצוע פעולה כזו, הורידי ופתחי את קובץ האקסל המלא עבור מודעת ה\"לזכרה\" של בליי -  הורידי את <a href=\"https://programminghistorian.org/assets/tf-idf/lesson-files.zip\">קבצים אלו</a>, חלצי את ארכיב ה-\".zip\" ופתחי את הקובץ \"bly_tfidf_all.xlsx\".</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style='text-align: right;'>&#x202b;כיצד להריץ בפייתון 3</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;בחלק זה של השיעור, אעבור על הצעדים שהצגתי עבור חישוב ערכי ה-tf-idf, עבור כל המילים על פני כל המסמכים בקורפוס שלנו. אם תרצי לעקוב, תוכלי להוריד את קבצי השיעור, לחלץ את ארכיב ה-\".zip\", ולהריץ את מחברת ה-Jupyter בתוך תיקיית ה-\"lesson\". תוכלי גם ליצור מחברת Jupyter חדשה באותו מיקום, ולהעתיק/להדביק קטעי קוד מהשיעור הזה לאורך הדרך. אם את משתמשת באנקונדה, בקרי <a href=\"https://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/execute.html\">בעמוד התיעוד של מחברות Jupyter</a> למידע נוסף על שינוי מקום האתחול של מחברת Jupyter. כמו ברוב שפות התכנות, ישנה יותר מדרך אחת לעשות את כל  אחד מהשלבים בהם אדון למטה.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;בלוק הקוד הראשון שנראה תוכנן למצוא את כל שמות הקבצים עבור כל קבצי \".txt\" בתיקייה \"txt\". שורות הקוד הבאות מייבאות את מחלקת ה-<code>Path</code> מספריית <code>pathlib</code> ומשתמשות במתודה <bdo><code>Path().rglob()</code></bdo> על-מנת ליצור רשימה של כל הקבצים בתיקיית \"txt\" שמסתיימים עם \".txt\". הספרייה  <code>pathlib</code> גם תצרף את מיקום התקייה <code>file.parent</code> אל כל שם קובץ על-מנת לספק נתיבים מלאים לכל קובץ (הן ב-Windows והן ב-MacOS).</p>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;על-ידי שימוש בשיטה הנ\"ל, אני מחבר כל שם קובץ לרשימה הנקראת <code>all_txt_files</code>. לבסוף, אני מחזיר את האורך של <code>all_txt_files</code> על-מנת לוודא שמצאתי את כל 366 שמות הקבצים. גישת ה\"רוץ-בלולאה-וצרף\" הזו מאוד שכיחה בפייתון.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "366\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "all_txt_files =[]\n",
    "for file in Path(\"txt\").rglob(\"*.txt\"):\n",
    "     all_txt_files.append(file.parent / file.name)\n",
    "# counts the length of the list\n",
    "n_files = len(all_txt_files)\n",
    "print(n_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;הערה מהירה לגבי שמות משתנים. שתי שיטות <a href=\"https://he.wikipedia.org/wiki/%D7%A9%D7%99%D7%95%D7%9D\">שיום</a> המשתנים הנפוצות ביותר מתעדפות נוחות ומשמעות סמנטית בהתאמה. לנוחות, ניתן לקרוא למשתנה <code>x</code> וכך יהיה קל ומהר יותר להקליד את שמו כשנצטרך להתייחס אליו. שמות סמנטיים, לעומת זאת, מנסים לתאר פעולה או מטרה. על-ידי קריאה לרשימת כל קבצי הטקסט <code>all_txt_files</code> ולמשתנה שמייצג את מספר הקבצים <code>n_files</code>, אני מתעדף משמעות סמנטית. יחד עם זאת, אני משתמש בקיצורים כמו <code>txt</code> לטקסט ו-<code>n</code> למספר (number) כדי לחסוך בהקלדה, או משתמש ב-<code>all_txt_file</code> במקום ב-<code>all_txt_file_names</code> בגלל שקצרנות עדיין חשובה. נורמות של שימוש בקו תחתון ואותיות גדולות מוסברות ב-PEP-8, מדריך הסגנון הרשמי של פייתון. כדאי לך להכיר אותו (9).</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;משלל סיבות, אנו רוצים למיין את הקבצים שלנו לפי סדר מספרי עולה, היות ויש לנו קובץ עבור כל יום בחודש ועבור כל חודש בשנה. אנו יכולים להשתמש במתודה <bdo><code>sort()</code></bdo> על-מנת למיין את הקבצים בסדר מספרי עולה ולהדפיס את השם הקובץ הראשון על-מנת לוודא שהוא אכן הקובץ \"txt.0101.txt\". </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('txt/0101.txt')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_txt_files.sort()\n",
    "all_txt_files[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;כעת, אנו יכולים להשתמש ברשימת שמות הקבצים שלנו על-מנת לטעון כל קובץ ולהמיר אותם לפורמט שפייתון יכול לקרוא ולהבין כטקסט. בקטע הקוד הבא, אני משתמש בפעולת \"רוץ-בלולאה-וצרף\" נופסת. הפעם, הלולאה רצה על רשימת שמות הקבצים ופותחת כל קובץ. אני משתמש במתודת ה-<bdo><code>read()</code></bdo> של פייתון על-מנת להמיר כל קובץ טקסט למחרוזת <code>(str)</code>, שזו הדרך בה פייתון יודע לחשוב על הנתונים כטקסט. אני מצרף את כל המחרוזות, אחת אחת, לרשימה חדשה שנקראת <code>all_docs</code>. נקודה חשובה - אובייקטי המחרוזת ברשימה הזו מסודרים באותו סדר שבו מסודרים שמות הקבצים ברשימה <code>all_txt_files</code>.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_docs = []\n",
    "for txt_file in all_txt_files:\n",
    "    with open(txt_file) as f:\n",
    "        txt_file_as_string = f.read()\n",
    "    all_docs.append(txt_file_as_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;זוהי כל העבודה המקדימה לה אנו נדרשים. שלבי עיבוד טקסט כמו <a href=\"https://en.wikipedia.org/wiki/Lexical_analysis#Tokenization\">טוקניזציה</a> והסרת סימני פיסוק תתבצע באופן אוטומטי כשנשתמש במחלקה <code>TfidfVectorizer</code> של Scikit-Learn על-מנת להמיר מסמכים מתוך רשימה של מחרוזות לציוני tf-idf. ניתן גם לספק רשימה של מילות-עצירה (מילים בשימוש שכיח שאת רוצה להתעלם מהן). על-מנת לבצע טוקניזציה ולהסיר מילות-עצירה בשפות שאינן אנגלית, את צריכה לבצע עיבוד מקדים על הטקסט עם ספריית פייתון אחרת או לספק טוקנייזר (שמבצע טוקניזציה) מותאם (ספציפית לאותה שפה - ת.פ.) ורשימת מילות-עצירה מתאימה, כאשר תשתמשי ב-<code>TfidfVectorizer</code>. קטע הקוד הבא מייבא את <code>TfidfVectorizer</code> מספריית Scikit-Learn, שמגיעה מותקנת מראש באנקונדה. <code>TfidfVectorizer</code> היא מחלקה (שנכתבה באמצעות תכנות מונחה-עצמים), ולכן אני מאתחל אותה עם פרמטרים ספציפיים כמשתנה בשם <code>vectorizer</code>. (ארחיב על הגדרות אלו בסעיף בהמשך הקרוי \"הגדרות Scikit-Learn\"). אחר-כך, אני מריץ את המתודה <bdo><code>fit_transform()</code></bdo> של האובייקט על רשימת המחרוזות שלי (משתנה בשם <code>all_docs</code>). המשתנה <code>X</code> הוא הפלט של המתודה <bdo><code>fit_transoform()</code></bdo>.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the TfidfVectorizer from Scikit-Learn.\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=.65, min_df=1, stop_words=None, use_idf=True, norm=None)\n",
    "transformed_documents = vectorizer.fit_transform(all_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;מתודת ה-<bdo><code>fit_transform()</code></bdo> הנ\"ל ממירה את רשימת המחרוזות לאובייקט הקרוי <a href=\"https://he.wikipedia.org/wiki/%D7%9E%D7%98%D7%A8%D7%99%D7%A6%D7%94_%D7%93%D7%9C%D7%99%D7%9C%D7%94\">מטריצה דלילה</a>. במקרה הזה, המטריצה מייצגת את ערכי ה-tf-idf לכל הטקסטים. מטריצות דלילות חוסכות בזיכרון על-ידי אי-שמירה של אפסים, אבל אנו רוצים גישה לאלו, אז קטע הקוד הבא משתמש במתודת ה-<bdo><code>toarray()</code></bdo> על-מנת להמיר את המטריצות הדלילות ל-<a href=\"https://docs.scipy.org/doc/numpy/reference/generated/numpy.array.html\">מערך Numpy</a>. אנחנו יכולים להדפיס את האורך של המערך על-מנת לוודא שהוא באותו אורך כמו רשימת המסמכים שלנו.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "366"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_documents_as_array = transformed_documents.toarray()\n",
    "# use this line of code to verify that the numpy array represents the same number of documents that we have in the file list\n",
    "len(transformed_documents_as_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;מערך Numpy הוא אובייקט דמוי רשימה, אך לא בדיוק כמו רשימה, ואני יכול לכתוב מדריך שלם על ההבדלים, אבל ישנו רק היבט אחד של מערכי Numpy שאנו צריכים לדעת כרגע: הוא ממיר את הנתונים המאוחסנים ב-<code>transformed_documents</code> לפורמט בו מיוצג כל ציון tf-idf עבור כל מילה בכל מסמך. מטריצות דלילות, לעומת זאת, לא כוללות ציונים שערכם אפס.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;אנו רוצים שכל מילה תהיה מיוצגת כך שלכל מסמך יהיה את אותו מספר הערכים, אחד עבור כל מילה בקורפוס. כל איבר ב-<code>transformed_documents_as_array</code> הוא מערך בעצמו המייצג מסמך אחד מהקורפוס שלנו. כתוצאה מכך, יש לנו למעשה רשת בה כל שורה מייצגת מסמך וכל עמודה מייצגת מילה. דמייני טבלה אחת מגיליון אלקטרוני המייצגת כל מסמך, כמו הטבלאות למעלה, אבל ללא תוויות על העמודות או השורות.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;על-מנת למזג את הערכים עם התוויות שלהם, אנו צריכים שתי פיסות מידע: סדר המסמכים, והסדר בו דירוגי מילים רשומים. את הסדר של המסמכים קל לדעת, כי זהו אותו סדר של המשתנה <code>all_docs_list</code>. רשימת המילים המלאה שמורה במשתנה ה-<code>vectorizer</code> שלנו, והיא באותו סדר בו כל איבר שומר ערכים ב-<code>transformed_documents_as_array</code>. אנו יכולים להשתמש במתודת ה-<bdo><code>get_feature_names()</code></bdo> של המחלקה <code>TfidfVectorizer</code> על-מנת לקבל את הרשימה הזו, ואז כל שורת נתונים (המהווה את ציוני ה-tf-idf של מסמך) ניתנת לאיחוד מחדש עם רשימת המילים. (לעוד פרטים על מסגרות נתונים של pandas, ראי את השיעור <a href=\"https://programminghistorian.org/en/lessons/visualizing-with-bokeh\">ויזואליזציה של נתונים עם Bokeh ועם Pandas</a>.)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# make the output folder if it doesn't already exist\n",
    "Path(\"./tf_idf_output\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# construct a list of output file paths using the previous list of text files the relative path for tf_idf_output\n",
    "output_filenames = [str(txt_file).replace(\".txt\", \".csv\").replace(\"txt/\", \"tf_idf_output/\") for txt_file in all_txt_files]\n",
    "\n",
    "# loop each item in transformed_documents_as_array, using enumerate to keep track of the current position\n",
    "for counter, doc in enumerate(transformed_documents_as_array):\n",
    "    # construct a dataframe\n",
    "    tf_idf_tuples = list(zip(vectorizer.get_feature_names(), doc))\n",
    "    one_doc_as_df = pd.DataFrame.from_records(tf_idf_tuples, columns=['term', 'score']).sort_values(by='score', ascending=False).reset_index(drop=True)\n",
    "\n",
    "    # output to a csv using the enumerated value for the filename\n",
    "    one_doc_as_df.to_csv(output_filenames[counter])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;לקטע הקוד הבא ישנם שלושה חלקים:</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;<ol dir=RTL>\n",
    "    <li>\n",
    "        לאחר שייבאנו את ספריית Pandas, הוא מחפש ספרייה בשם \"tf_idf_output\" ויוצר אותה אם אינה קיימת.\n",
    "    </li>\n",
    "    <li>\n",
    "        הוא לוקח את רשימת קבצי ה-\".txt\" מקטע קוד קודם שהראיתי, ומשתמשת בה כדי להרכיב נתיב לקובץ \".csv\" לכל קובץ \".txt\". משתנה ה-<code>output_filenames</code>, לדוגמה, ימיר את \"txt/0101.txt\" (הנתיב של קובץ ה\".txt\" הראשון) ל-\"tf_idf_output/0101.csv\" וכך הלאה והלאה עבור כל קובץ.\n",
    "    </li>\n",
    "    <li>\n",
    "     באמצעות שימוש בלולאה, הקוד ממזג כל וקטור של ציוני tf-idf עם שמות המאפיינים מ-<code>vectorizer</code>, ממיר כל זוג (מיזוג של מילה/ציון) למסגרת הנתונים של Pandas, ושומר כל מסגרת נתונים בקובץ ה-\".csv\" המתאים לה. \n",
    "    </li>\n",
    "</ol></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style='text-align: right;'>&#x202b;פירוש רשימות מילים: המלצות ואזהרות</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;אחרי שהרצת את קטעי הקוד הנ\"ל, תהיה לך תיקייה בשם \"tf_idf_output\" עם 366 קבצי \".csv\" בתוכה. כל קובץ מתאים למודעת \"לזכרו\" מסויימת בתיקייה \"txt\", וכל אחד מכיל רשימה של מילים עם ציוני tf-idf לאותו מסמך. כפי שראינו עם המודעה של נלי בליי, רשימות המילים הללו יכולות להיות מאוד אינדיקיטביות; אמנם, זה חשוב להבין שפרשנות-יתר של התוצאות שקיבלנו יכולה למעשה לשבש את ההבנה שלך לגבי הטקסט החבוי.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;בכלליות, מוטב להתחיל עם הרעיונות שרשימות המילים האלו יועילו להעלאת היפותזות או שאלות מחקר. Tf-idf  גורר, אך לאו דווקא יפיק, טענות חד-משמעיות. לדוגמה, הרכבתי רשימה של מועדות \"לזכרם\" של דמויות מסוף המאה ה-19 - תחילת המאה ה-20 שכולן עבדו בעיתונים וכתבי עת והיה להן קשר כלשהו לרפורמות חברתיות. הרשימה שלי כוללת את נלי בליי, <a href=\"https://he.wikipedia.org/wiki/%D7%95%D7%99%D7%9C%D7%94_%D7%A7%D7%90%D7%AA%D7%A8\">וילה קאתר</a>, <a href=\"https://he.wikipedia.org/wiki/%D7%95%D7%99%D7%9C%D7%99%D7%90%D7%9D_%D7%90%D7%93%D7%95%D7%90%D7%A8%D7%93_%D7%91%D7%95%D7%A8%D7%92%D7%94%D7%A8%D7%93_%D7%93%D7%95_%D7%91%D7%95%D7%99%D7%96\">ויליאם אדוארד בורגהרד דו בויז</a>, <a href=\"https://he.wikipedia.org/wiki/%D7%90%D7%A4%D7%98%D7%95%D7%9F_%D7%A1%D7%99%D7%A0%D7%A7%D7%9C%D7%A8\">אפטון סינקליר</a>, <a href=\"https://en.wikipedia.org/wiki/Ida_Tarbell\">אידה טרבל</a>, אך ייתכן וישנם דמויות נוספות בקורפוס שמתאימות לאותם הקריטריונים. (10)</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;תחילה ציפיתי לראות הרבה מילים משותפות, אבל הופתעתי. המילים הדומיננטיות בכל רשימה הן מילים עם גוון אינדיבידואלי (שמות אנשים, שמות מקומות, שמות חברות וכדומה) אך יכולתי לסנן אותן החוצה באמצעות הגדרות ה-tf-idf שלי, או פשוט להתעלם מהן. בו-זמנית, אני יכול לחפש מילים שמעידות חד-משמעית על קשריהן של כל דמות למקצוע הכתיבה. (החלק של שיעור זה הקרוי \"הגדרות Scikit-Learn\" מרחיב על כיצד ניתן להתייחס לישות בעלת שם או ביטוי כאסימון (טוקן) יחיד). הטבלה הבאה מראה את 20 המילים עם ציוני ה-tf-idf הגבוהים ביותר לכל מודעה:</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"width:100%\">\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>Tf-idf Rank</td>\n",
    "      <td>Nellie Bly</td>\n",
    "      <td>Willa Cather</td>\n",
    "      <td>W.E.B. Du Bois</td>\n",
    "      <td>Upton Sinclair</td>\n",
    "      <td>Ida Tarbell</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>1</td>\n",
    "      <td>cochrane</td>\n",
    "      <td>cather</td>\n",
    "      <td>dubois</td>\n",
    "      <td>sinclair</td>\n",
    "      <td>tarbell</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>2</td>\n",
    "      <td>her</td>\n",
    "      <td>her</td>\n",
    "      <td>dr</td>\n",
    "      <td>socialist</td>\n",
    "      <td>she</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>3</td>\n",
    "      <td>she</td>\n",
    "      <td>she</td>\n",
    "      <td>negro</td>\n",
    "      <td>upton</td>\n",
    "      <td>her</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>4</td>\n",
    "      <td>seaman</td>\n",
    "      <td>nebraska</td>\n",
    "      <td>ghana</td>\n",
    "      <td><strong>books</strong></td>\n",
    "      <td>lincoln</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>5</td>\n",
    "      <td>bly</td>\n",
    "      <td>miss</td>\n",
    "      <td>peace</td>\n",
    "      <td>lanny</td>\n",
    "      <td>miss</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>6</td>\n",
    "      <td>nellie</td>\n",
    "      <td>forrester</td>\n",
    "      <td><strong>encyclopedia</strong></td>\n",
    "      <td>social</td>\n",
    "      <td>oil</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>7</td>\n",
    "      <td>mark</td>\n",
    "      <td>sibert</td>\n",
    "      <td>communist</td>\n",
    "      <td>budd</td>\n",
    "      <td>abraham</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>8</td>\n",
    "      <td>ironclad</td>\n",
    "      <td>twilights</td>\n",
    "      <td>barrington</td>\n",
    "      <td>jungle</td>\n",
    "      <td>mcclure</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>9</td>\n",
    "      <td><strong>plume</strong></td>\n",
    "      <td>willa</td>\n",
    "      <td>fisk</td>\n",
    "      <td>brass</td>\n",
    "      <td>easton</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>10</td>\n",
    "      <td>vexations</td>\n",
    "      <td>antonia</td>\n",
    "      <td>atlanta</td>\n",
    "      <td>california</td>\n",
    "      <td><strong>volumes</strong></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>11</td>\n",
    "      <td>phileas</td>\n",
    "      <td>mcclure</td>\n",
    "      <td>folk</td>\n",
    "      <td><strong>writer</strong></td>\n",
    "      <td>minerva</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>12</td>\n",
    "      <td>597</td>\n",
    "      <td><strong>novels</strong></td>\n",
    "      <td>booker</td>\n",
    "      <td>vanzetti</td>\n",
    "      <td>standard</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>13</td>\n",
    "      <td>elizabeth</td>\n",
    "      <td>pioneers</td>\n",
    "      <td>successively</td>\n",
    "      <td>macfadden</td>\n",
    "      <td>business</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>14</td>\n",
    "      <td><strong>nom</strong></td>\n",
    "      <td>cloud</td>\n",
    "      <td>souls</td>\n",
    "      <td>sacco</td>\n",
    "      <td>titusville</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>15</td>\n",
    "      <td>balloon</td>\n",
    "      <td><strong>book</strong></td>\n",
    "      <td>council</td>\n",
    "      <td><strong>wrote</strong></td>\n",
    "      <td><strong>articles</strong></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>16</td>\n",
    "      <td>forgeries</td>\n",
    "      <td>calif</td>\n",
    "      <td>party</td>\n",
    "      <td>meat</td>\n",
    "      <td>bridgeport</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>17</td>\n",
    "      <td>mcalpin</td>\n",
    "      <td><strong>novel</strong></td>\n",
    "      <td>disagreed</td>\n",
    "      <td><strong>pamphlets</strong></td>\n",
    "      <td>expose</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>18</td>\n",
    "      <td>asylum</td>\n",
    "      <td>southwest</td>\n",
    "      <td>harvard</td>\n",
    "      <td>my</td>\n",
    "      <td>trusts</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>19</td>\n",
    "      <td>fogg</td>\n",
    "      <td><strong>verse</strong></td>\n",
    "      <td><strong>arts</strong></td>\n",
    "      <td>industry</td>\n",
    "      <td>mme</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>20</td>\n",
    "      <td>verne</td>\n",
    "      <td><strong>wrote</strong></td>\n",
    "      <td>soviet</td>\n",
    "      <td><strong>novel</strong></td>\n",
    "      <td><strong>magazine</strong></td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;השתמשתי בגופן מודגש על-מנת לסמן מילים שנראות כמעידות חד-משמעית על קשר לכתיבה. הרשימה כוללת מילים כמו <i>articles, arts, book, book, books, encyclopedia, magazine, nom, novel, novels, pamphlets, plume, verse, volumes, writer</i> ו- <i>wrote</i>, אבל ניתן להרחיב אותה לכלול אזכורים לשמות כתבי עת או ספרים ספציפיים. אם נניח לרגע בצד היבטים  מסובכים כאלו, זה מדהים בעיניי שברשימות של קאתר וסינקליר ישנן כל כך הרבה מילים עבור \"ספרים\" ו\"כתיבה\", בעוד שאצל בליי, דו בויז וטרבל לא.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;אני בקלות יכול לקפוץ למסקנות. נראה שהזהות של קאתר מקושרת הכי הרבה אל המגדר שלה, תחושתה לגבי מקומה, כתביה הבדיוניים והשירה. זהותו של סינקליר נראית מקושרת אף יותר אל הפוליטיקה בה עסק, ואל כתביו על בשר, תעשייה, ואל המשפט וההוצאה להורג הידועים והשנויים במחלוקת של ניקולה סאקו וברתולומאו ונצטי. בליי מקושרת לשם העט שלה, אל בעלה, ואל כתביה על בתי מחסה. דו בויז מקושר לגזע ואל הקריירה האקדמית שלו. טרבל מתוארת על-ידי הנושאים שכתבה עליהם: עסקים, קרנות, חברת Standard Oil ואברהם לינקולן. אני יכול לטעון שמגדר הוא אלמנט עם מובהקות גדולה יותר אצל נשים מאשר אצל גברים; גזע היא מילה מובילה אצל האמריקאי-אפריקאי היחידה בקבוצה שבחנתי.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;כל אחת מהאבחנות הללו מהווה את הבסיס לשאלה עמוקה יותר, אבל הפרטים הללו אינם מספיקים כדי לבצע הכללות. ראשית כל, אני צריך להתחשב בהאם הגדרות ה-tf-idf שלי יוצרות השפעות  שיעלמו תחת תנאים אחרים; תוצאות רובסטיות צריכות להיות יציבות דיו כדי להתקיים עם שלל הגדרות. (חלק מההגדרות הללו נדונות בסעיף \"הגדרות Scikit-Learn\" בהמשך). כמו כן, אני צריך לקרוא לפחות את חלק מהמודעות כדי לוודא שאני לא מקבל אותות שגויים ממילים כאלו או אחרות. אם אקרא את המודעה של דו בויז, לדוגמה, אני עשוי לגלות שאזכורים של העבודה שלו \"The Encyclopedia of the Negro\", תורמת לפחות חלקית לציון הכולל של המילה <i>negro</i>.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;כמו כן, אני יכול לגלות שהמודעה של בליי אכן כוללת מילים כמו <i>journalism, journalistic, newspapers,</i>  ו- <i>writing</i>, אבל המודעה קצרה מאוד, מה שאומר שמרבית המילים המוזכרות בה מופיעות רק פעם או פעמיים, מה שאומר שסביר מאוד שמילים עם ציוני idf גבוהים מאוד ידורגו בראש הרשימה. אני מאוד רוצה שערכי ה-tf וערכי ה-idf יהיו מאוזנים, כך שאוכל לפסול מילים שמופיעות רק במעט מסמכים, או שאני יכול להתעלם מתוצאות לגבי מודעות שמכילות מספר מילים נמוך מרף מסוים.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;לסיום, אני יכול לתכנן מבדקים עבור שאלות כמו: האם יותר סביר כי מודעות של אמריקאים-אפריקאים יזכירו מילים המקושרות לגזע? אני חושב שהההנחה שכן היא היא השערה טובה, אבל עדיין עליי להמשיך לכפוף את ההכללות שלי לבדיקה לפני שאגבש מסקנות. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style='text-align: right;'>&#x202b;מספר דרכים בהן ניתן להשתמש ב-TF-IDF בהיסטוריה חישובית</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;כפי שתארתי, מקורותיה של שיטת ה-tf-idf היא בתחום אחזור המידע, והרעיון של למשקל תדירות מילים ביחס למספר המסמכים בקורפוס ממשיך להיות בשימוש בשלל היבטים של יישומי רשת בחיי היום-יום, בייחוד במנועי חיפוש מבוססי-טקסט. יחד עם זאת, בהקשר של אנליטיקה תרבותית או היסטוריה חישובית, TF-IDF מתאים לאוסף מאוד מסוים של מטלות. שימושים אלו נוטים להתחלק לאחת משלוש קבוצות:</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <p style='text-align: right;'>&#x202b;1. ככלי חקירה או טכניקת ויזואליזציה</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;כפי שכבר הדגמתי, רשימות מילים יחד עם ציוני tf-idf לכל מסמך בקורפוס יכולות כשלעצמן להוות עזר משמעותי לצורך פירוש המידע, והן יכולות לעזור בהעלאת השערות או שאלות מחקר. רשימות מילים עשויות להוות גם את הלבנים איתן  בונים שיטות מתוחכמות יותר של אסטרגיות ויזואליזציה ודפדוף (במקור browsing - ת.פ.). <a href=\"http://jonathanstray.com/a-full-text-visualization-of-the-iraq-war-logs\">ויזואליזציית טקסט מלאה של יומני מלחמת עיראק</a>, מאת ג'ונתן סטריי וג'וליאן בורג'ס, מהווה דוגמה טובה לשימוש כזה (11). על-ידי שימוש במאפיינים שעברו טרנספורמציית tf-idf, סטריי ובורג'ס בנו רשת ויזואליזציה שממקמת את יומני מלחמת עיראק למול מילות המפתח הכי מובהקות בהם. דרך זו של ויזואליזציה טקסטואלית של מידע הובילה את סטריי לפתח את <a href=\"https://www.overviewdocs.com/\">The Overview Project</a>, שמספק ממשק למשתמשים שמאפשר לבצע ויזואליזציה וחיפוש של אלפי מסמכים ביחד. אנו יכולים להשתמש בגישה מסוג זה ליצור גרף של המודעות בקורפוס שלנו ולבדוק האם קיימות התקבצויות של מילות מפתח.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <p style='text-align: right;'>&#x202b;2. דמיון טקסטואלי וקבוצות מאפיינים</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;מאחר ו-tf-idf בדרך-כלל תניב ציונים נמוכים יותר למילות פונקציה בעלות תדירות שימוש גבוה וציונים גבוהים למילים הקשורות לנושא הטקסט, השיטה הולמת לשימוש במשימות הכוללות דמיון טקסטואלי. מנוע חיפוש לעיתים קרובות ישתמש ב-tf-idf על קורפוס ויחזיר תוצאות מדורגות לחיפושי המשתמשת על-ידי חיפוש אחר מסמכים עם <a href=\"https://en.wikipedia.org/wiki/Cosine_similarity\">דמיון הקוסינוס</a> הגבוה ביותר למחרוזת החיפוש של המשתמשת. באותו ההיגיון ניתן להשתמש כדי לשאול שאלה כמו \"איזו מודעה בקורפוס שלנו היא הכי דומה למודעה של נלי בליי?\"</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;באופן דומה, אנו יכולים להשתמש ב-tf-idf כדי לגלות מיהן המילים בעלות ציון הקשר למסמך או קבוצת מסמכים הגבוה ביותר. לדוגמה, אני יכול לאסוף מבחר של מודעות על עיתונאים (כולל בליי) ולאחד אותן למסמך אחד גדול בטרם אריץ את שיטת ה-tf-idf. הפלט למסמך הזה יהווה כעת היוריסטיקה למילים בעלות מובהקות ביחס למודעות העיתונאים שלי, כאשר אערוך השוואה למודעות אחרות בקורפוס. אוכל להשתמש ברשימת מילים כזו למגוון של משימות חישוביות שונות.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <p style='text-align: right;'>&#x202b;3. כשלב עיבוד מקדים</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;הפסקאות הנ\"ל מעידות על מדוע שימוש ב-tf-idf לעיבוד מקדים נעשה לעיתים קרובות כל-כך עם למידת מכונה. למאפיינים שעברו טרנספורמציית tf-idf יש נטייה לערך פרדיקטיבי גבוה מאשר לתדירויות גולמיות של הופעות מילים, במיוחד בשימוש במודל קלסיפיקציה של למידת מכונה מפוקחת, כאשר חלק מהסיבה היא ש-tf-idf נוטה להגביר את המשקל של מילים הקשורות לנושא ולהחליש את המשקל של מילות פונקציה בעלות תדירות גבוהה. יוצאת דופן בולטת לכך, היא הכללה של שיוך קרדיט ספרותי (במקור authorship attribution - ת.פ.), כאשר מילות פונקציה בעלות תדירות גבוהה הן דווקא כן בעלות ערך פרדיקטיבי גבוה. כפי שאראה ב\"הגדרות Scikit-Learn\", שיטת ה-tf-idf יכולה לשמש לדילול רשימות מאפיינים של למידת מכונה, ולעיתים קרובות מודל עם מספר מועט של מאפיינים הוא רצוי.   </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style='text-align: right;'>&#x202b;וריאציות פוטנציאליות של TF-IDF</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <p style='text-align: right;'>&#x202b;הגדרות Scikit-Learn</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;למחלקה <code>TfidfVectorizer</code> של הספרייה Scikit-Learn ישנן כל-מיני הגדרות פנימיות שניתן לכוונן על-מנת להשפיע על הפלט. ככלל, להגדרות אלו יש יתרונות וחסרונות; אין דרך יחידה ונכונה להגדיר אותם. במקום זאת, הדבר המומלץ לעשות הוא להבין בדיוק מה כל הגדרה עושה כדי שתוכלי לתאר ולהסביר את הבחירות שעשית לגביהן. רשימת הפרמטרים המלאה מתוארת <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">בדוקיומנטציה של Scikit-Learn</a>, אבל נציג להלן את ההגדרות החשובות ביותר:</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <p style='text-align: right;'>&#x202b;1. מילות עצירה</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;בקוד שלי, השתמשתי ב-<code>stop_words=None</code>, אבל ניתן להשתמש גם ב-<bdo><code>stop_words='english'</code></bdo>. ההגדרה הזו תסנן מילים על-ידי שימוש <a href=\"https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/feature_extraction/_stop_words.py\">ברשימה שנבחרה מראש</a> של מילות פונקציה בעלות תדירות גבוהה כמו 'the', 'to' ו-'of'. בהתאם להגדרות שלך, הרבה מן המילים הללו יקבלו ציוני tf-idf נמוכים בכל מקרה בגלל שהן נוטות להופיע בכל המסמכים. לדיון על כמה רשימות זמינות של מילות עצירה (כולל של Scikit-Learn) ראי את <a href=\"https://aclweb.org/anthology/W18-2502\">\"רשימות מילות עצירה בחבילות תוכנה חופשיות עם קוד פתוח\"</a>.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <p style='text-align: right;'>&#x202b;2.  min_df, max_df</p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;הגדרות אלו שולטות במספר המינימלי של מסמכים בהם מילה <i>חייבת</i> להימצא על-מנת להיכלל, ומספר המקסימלי של מסמכים בהם מילה <i>יכולה</i> להימצא על-מנת להיכלל. כל אחת מן ההגדרות הללו מקבלת כערכים מספר דצימלי בין 0 ל-1 המעיד על אחוז הסף, או מספר שלם המייצג את תדירות ההופעה הגולמית. הגדרת <code>max_df</code> מתחת ל-0.9 בדרך-כלל יסיר את רוב, אם לא כל, מילות העצירה. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <p style='text-align: right;'>&#x202b;3. max_features</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;הפרמטר הזה ניתן לשימוש כדרך לסנן החוצה מילים לפי תדירותן, עוד טרם הרצת ה-tf-idf. הוא יכול להיות יעיל במיוחד בהקשרים של למידת מכונה כשאת רוצה שלא לעבור רף מקסימלי של מספר מומלץ של מאפיינים למילה. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <p style='text-align: right;'>&#x202b;4. norm, smooth_idf, ו- sublinear_tf</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;כל אחד מאלו ישפיע על טווח הציונים הנומריים שאלגוריתם ה-tf-idf יחזיר כפלט. <code>norm</code> תומך בנרמול באמצעות נורמות ה-L1 ו-L2, עליהן תוכלי לקרוא ב-<a href=\"https://machinelearningmastery.com/vector-norms-machine-learning/\">machinelearningmastery.com</a>. כמו כן, <code>smooth_idf</code> מוסיף $1$ לכל ציון תדירות מסמך באופן כזה ש\"מסמך נוסף נראה מכיל כל מילה באוסף בדיוק פעם אחת\". <code>sublinear_tf</code> מפעיל טנרספורמצייה נוספת על-ידי החלפת tf ב-log(tf). למידע נוסף על שיטות החלקה (במקור smoothing - ת.פ.) ונרמול של tf-idf, ראי את (12).</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <p style='text-align: right;'>&#x202b;מעבר למאפייני מילים</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;מאחר והרעיון הבסיסי מאחורי <b>tf-idf</b> הוא למשקל ספירות מילים ביחס למספר המסמכים בהם המילים מופיעות, ניתן להשתמש באותו ההיגיון עם מאפיינים מבוססי טקסט אחרים. לדוגמה, זה יחסית פשוט לשלב את <b>tf-idf</b> עם תהליכים הנקראים <a href=\"https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html\">Stemming (מלשון גזע - ת.פ.) ולמטיזציה</a>. שני התהליכים האלו הן שתי דרכים נפוצות לקבץ יחדיו צורות מילים/הטיות מילים שונות. לדוגמה, הגזע הן של <i>happy</i> והן של <i>happiness</i> הוא <i>happi</i>, והלמה של שתי המילים היא <i>happy</i>. לאחר ביצוע אחד מהתהליכים, ספירות גזעי מילים או למות ניתנות להחלפה בספירות מילים, וניתן להפעיל את טרנספורמציית ה-<bdo><b>(s/l)f-idf</b></bdo>. לכל גזע מילה או למה יהיה ציון <b>df</b> גבוה יותר מלכל אחת מהמילים אותן הוא מקבץ, כך שלמות וגזעי מילה יחד עם הרבה וריאציות מילים שונות ייטו לקבל ציוני <b>tf-idf</b> נמוכים יותר.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;באופן דומה, טנרספורמציית ה-tf-idf ניתנת ליישום על <a href=\"https://en.wikipedia.org/wiki/N-gram\"> n-grams</a>. פרסום ממרץ 2016 באתר Fivethirtyeight.com הנקרא <a href=\"https://fivethirtyeight.com/features/these-are-the-phrases-each-gop-candidate-repeats-most/\">\"אלו הם הביטויים שכל מועמד במפלגה הרפובליקנית חוזר עליהם הכי הרבה\"</a> משתמש בגישה כזו לביצוע חישוב תדירות המסמך ההפכית על ביטויים במקום על מילים (13). </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style='text-align: right;'>&#x202b;TF-IDF וחלופות נפוצות</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;<b>Tf-idf</b> ניתן להשוואה עם שיטות נוספות לבידוד ו/או דירוג של מאפייני מילה חשובים במסמך או אוסף של מסמכים. סעיף זה מספק אזכור קצר של ארבע שיטות קשורות אך שונות שמתייחסות להיבטים דומים - אך לא זהים - של מידע טקסטואלי.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <p style='text-align: right;'>&#x202b;1. Keyness</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;Keyness זהו ביטוי כוללני למקבץ של שיטות סטטיסטיות שמנסות לספק אינדיקציה לחשיבות המספרית של מילה ביחס למסמך או אוסף של מסמכים, בהשוואה ישירה לאוסף גדול יותר של מסמך או קורפוס. כתלות של כיצד אנו מגדירים את טרנספורמציית ה-<b>tf-idf</b>, היא עשויה לבודד רבים מהמאפיינים החשובים ביותר במסמך, אך <b>tf-idf</b> אינה מדוייקת כמו השיטות השכיחות ביותר של Keyness. במקום לשנות את ציוני תדירות מילים במסמך, keyness מפיקה ערך נומרי המעיד על כמה טיפוסי או לא טיפוסי מבחינה סטטיסטית השימוש במילה בטקסט. בעזרת <a href=\"https://he.wikipedia.org/wiki/%D7%9E%D7%91%D7%97%D7%9F_%D7%9B%D7%99_%D7%91%D7%A8%D7%99%D7%91%D7%95%D7%A2\"> מבחן כי בריבוע</a>, לדוגמה, אנו יכולים לשערך את טיב היחסים בין תדירות מילה לבין נורמה מבוססת, ולגזור <a href=\"https://he.wikipedia.org/wiki/%D7%A2%D7%A8%D7%9A-p\"> ערך-p</a> המעיד על ההסתברות להתקל בהפרש הנמדד בדגימה אקראית. למידע נוסף על keyness, ראי את (14). </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <p style='text-align: right;'>&#x202b;2. מודלי נושא</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;מידול נושאים ו-<b>tf-idf</b> הן טכניקות שונות מאוד, אבל לדעתי, אנשים החדשים לתחום מדעי הרוח הדיגיטליים רוצים לעיתים קרובות להריץ מידול נושאים על קורפוס כשלב ראשון, ולפחות בחלק מהמקרים הללו, להריץ <b>tf-idf</b> במקום לייצר מודלי נושאים יהיה עדיף יותר (15). <b>Tf-idf</b> מתאימה במיוחד אם את מחפשת אחר דרך לקבל מבט ממעוף הציפור על הקורפוס שלך בשלב מוקדם של המחקר שלך, היות והאלגוריתם הוא שקוף והתוצאות ניתנות לשחזור. כפי שבן שמידט מציע, חוקרים שמשתמשים במידול נושאים צריכים לדעת ש\"נושאים עלולים לא להיות קוהרנטיים כפי שהם מניחים\" (16). זו סיבה אחת מדוע <b>tf-idf</b> משולב לתוך <a href=\"https://www.overviewdocs.com/\">The Overview Project</a>. מודלי נושאים יכולים לעזור לחוקרים לחקור את הקורפוסים שלהם, ויש להם מספר יתרונות על-פני טכניקות אחרות, בעיקר זה שהם מציעים קטגוריות נרחבות, אבל זהו יתרון כללי של שיטות clustering לא מפוקחת. מודלי נושאים מושכים במיוחד בגלל שמסמכים מקבלים ציון לפי כמה הם מתאימים לכל נושא, ובגלל שנושאים מיוצגים כרשימות של מילים המופיעות זו עם זו, מה שמספק תחושה חזקה לגבי כיצד מילים מתקשרות למקבצים. יחד עם זאת, המודל ההסתברותי מאחורי מודלי נושאים הוא מתוחכם, וזה קל מאוד לעוות את תוצאותייך אם אינך מבינה מה את עושה. מאידך, המתמטיקה מאחורי <b>tf-idf</b> היא בהירה דיו כדי לייצג בגיליון אלקטרוני. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <p style='text-align: right;'>&#x202b;3. סיכום טקסט אוטומטי</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;סיכום טקסט זוהי דרך נוספת לחקור קורפוס. רדא מיכלצ'ה ופול טראו, לדוגמה, פרסמו את TextRank - \"מודל דירוג מבוסס-גרף לעיבוד טקסט\" עם תוצאות מבטיחות לגבי יישומים של חילוץ מילות מפתח ומשפטים (17). כמו עם מידול נושאים, TextRank ו-<b>tf-idf</b> דיי שונים בגישתם לאחזור מידע, אך ישנה חפיפה רבה בין המטרות של שני האלגוריתמים. ייתכן וזה ויתאים למחקר שלך, במיוחד אם המטרה שלך היא לקבל תחושה מהירה לגבי תוכן המסמכים לפני שתתכנני פרויקט גדול יותר.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <p style='text-align: right;'>&#x202b;אזכורים וקריאה נוספת</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Beckman, Milo. “These Are The Phrases Each GOP Candidate Repeats Most,” FiveThirtyEight, March 10, 2016. https://fivethirtyeight.com/features/these-are-the-phrases-each-gop-candidate-repeats-most/\n",
    "\n",
    "- Bennett, Jessica, and Amisha Padnani. “Overlooked,” March 8, 2018. https://www.nytimes.com/interactive/2018/obituaries/overlooked.html\n",
    "\n",
    "- Blei, David M., Andrew Y. Ng, and Michael I. Jordan, “Latent Dirichlet Allocation” Journal of Machine Learning Research 3 (January 2003): 993-1022.\n",
    "\n",
    "- Bondi, Marina, and Mike Scott, eds. Keyness in Texts. Philadelphia: John Benjamins, 2010.\n",
    "\n",
    "- Bowles, Nellie. “Overlooked No More: Karen Sparck Jones, Who Established the Basis for Search Engines” The New York Times, January 2, 2019. https://www.nytimes.com/2019/01/02/obituaries/karen-sparck-jones-overlooked.html\n",
    "\n",
    "- Documentation for TfidfVectorizer. https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "\n",
    "- Grimmer, Justin and King, Gary, Quantitative Discovery from Qualitative Information: A General-Purpose Document Clustering Methodology (2009). APSA 2009 Toronto Meeting Paper. Available at SSRN: https://ssrn.com/abstract=1450070\n",
    "\n",
    "- “Ida M. Tarbell, 86, Dies in Bridgeport” The New York Times, January 7, 1944, 17. https://www.nytimes.com\n",
    "\n",
    "- Manning, C.D., P. Raghavan, and H. Schütze, Introduction to Information Retrieval. Cambridge: Cambridge University Press, 2008.\n",
    "\n",
    "- Mihalcea, Rada, and Paul Tarau. “Textrank: Bringing order into text.” In Proceedings of the 2004 conference on empirical methods in natural language processing. 2004.\n",
    "\n",
    "- “Nellie Bly, Journalist, Dies of Pneumonia” The New York Times, January 28, 1922, 11. https://www.nytimes.com\n",
    "\n",
    "- Salton, G. and M.J. McGill, Introduction to Modern Information Retrieval. New York: McGraw-Hill, 1983.\n",
    "\n",
    "- Schmidt, Ben. “Do Digital Humanists Need to Understand Algorithms?” Debates in the Digital Humanities 2016. Online edition. Minneapois: University of Minnesota Press. http://dhdebates.gc.cuny.edu/debates/text/99\n",
    "\n",
    "- “Words Alone: Dismantling Topic Models in the Humanities,” Journal of Digital Humanities. Vol. 2, No. 1 (2012): n.p. http://journalofdigitalhumanities.org/2-1/words-alone-by-benjamin-m-schmidt/\n",
    "\n",
    "- Spärck Jones, Karen. “A Statistical Interpretation of Term Specificity and Its Application in Retrieval.” Journal of Documentation 28, no. 1 (1972): 11–21.\n",
    "\n",
    "- Stray, Jonathan, and Julian Burgess. “A Full-text Visualization of the Iraq War Logs,” December 10, 2010 (Update April 2012). http://jonathanstray.com/a-full-text-visualization-of-the-iraq-war-logs\n",
    "\n",
    "- Underwood, Ted. “Identifying diction that characterizes an author or genre: why Dunning’s may not be the best method,” The Stone and the Shell, November 9, 2011. https://tedunderwood.com/2011/11/09/identifying-the-terms-that-characterize-an-author-or-genre-why-dunnings-may-not-be-the-best-method/\n",
    "\n",
    "- “The Historical Significance of Textual Distances”, Preprint of LaTeCH-CLfL Workshop, COLING, Santa Fe, 2018. https://arxiv.org/abs/1807.00181\n",
    "\n",
    "- van Rossum, Guido, Barry Warsaw, and Nick Coghlan. “PEP 8 – Style Guide for Python Code.” July 5, 2001. Updated July 2013. https://www.python.org/dev/peps/pep-0008/\n",
    "\n",
    "- Whitman, Alden. “Upton Sinclair, Author, Dead; Crusader for Social Justice, 90” The New York Times, November 26, 1968, 1, 34. https://www.nytimes.com\n",
    "\n",
    "- “W. E. B. DuBois Dies in Ghana; Negro Leader and Author, 95” The New York Times, August 28, 1963, 27. https://www.nytimes.com\n",
    "\n",
    "- “Willa Cather Dies; Noted Novelist, 70” The New York Times, April 25, 1947, 21. https://www.nytimes.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style='text-align: right;'>&#x202b;אלטרנטיבות לאנקונדה</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;אם אינך משתמשת באנקונדה, תצטרכי לדאוג לנקודות הבאות:</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'>&#x202b;<ol dir=RTL>\n",
    "    <li>התקיני את פייתון 2 או 3 (בעדיפות לפייתון 3.6 או גרסה מאוחרת יותר).</li>\n",
    "    <li>מומלץ: התקיני והריצי סביבה וירטואלית.</li>\n",
    "    <li>התקיני את ספריית Scikit-Learn והתלויות שלה (ראי את <a href=\"http://scikit-learn.org/stable/install.html\">http://scikit-learn.org/stable/install.html</a>). </li>\n",
    "    <li>התקיני את מחברת Jupyter והתלויות שלה.</li>\n",
    "</ol></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <p style='text-align: right;'>&#x202b;הערות סיום</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Underwood, Ted. “Identifying diction that characterizes an author or genre: why Dunning’s may not be the best method,” The Stone and the Shell, November 9, 2011. https://tedunderwood.com/2011/11/09/identifying-the-terms-that-characterize-an-author-or-genre-why-dunnings-may-not-be-the-best-method/\n",
    "\n",
    "2. Bennett, Jessica, and Amisha Padnani. “Overlooked,” March 8, 2018. https://www.nytimes.com/interactive/2018/obituaries/overlooked.html\n",
    "\n",
    "3. <p style='text-align: right;'>&#x202b;מסד הנתונים הזה הוא מגרסה של האתר \"On This Day\" של ה-New York Times שלא עברה עדכון מאז ה-31 לינואר,2011 והוחלפה בבלוג חדיש יותר בכתובת <a href=\"https://learning.blogs.nytimes.com/on-this-day/\">https://learning.blogs.nytimes.com/on-this-day/</a>. מה שנשאר באתר \"On This Day\" הישן יותר זה קובץ .html סטטי לכל יום בשנה (0101.html, 0102.html, וכ')' כולל דף סטטי ל-29 בפברואר (0229.html). נראה שהתוכן הוחלף מתי שעודכן, ולכן אין ארכיונים של תוכן לפי שנה. ניתן להניח, שהרשומות \"On This Day\" עבור ה-1 לינואר עד ה-31 לינואר עודכנו לאחרונה בימים המתאימים להם ב-2011. יחד עם זאת, ה-1 לפברואר עד ה-31 לדצמבר ככל הנראה עודכנו לאחרונה בימים המתאימים להם ב-2010. הדף שמייצג את ה-29 בפברואר עודכן לאחרונה ככל הנראה ב-29 לפברואר 2008. </p>\n",
    "\n",
    "4. Spärck Jones, Karen. “A Statistical Interpretation of Term Specificity and Its Application in Retrieval.” Journal of Documentation vol. 28, no. 1 (1972): 16.\n",
    "\n",
    "5. Bowles, Nellie. “Overlooked No More: Karen Spärck Jones, Who Established the Basis for Search Engines” The New York Times, January 2, 2019. https://www.nytimes.com/2019/01/02/obituaries/karen-sparck-jones-overlooked.html\n",
    "\n",
    "6. “Nellie Bly, Journalist, Dies of Pneumonia” The New York Times, January 28, 1922, 11. https://www.nytimes.com\n",
    "\n",
    "7. <p style='text-align: right;'>&#x202b;תיעוד עבור <code>TfidfVecotrizer</code> להלן:<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html</a></p>\n",
    "\n",
    "8. Schmidt, Ben. “Do Digital Humanists Need to Understand Algorithms?” Debates in the Digital Humanities 2016. Online edition. (Minneapois: University of Minnesota Press): n.p. http://dhdebates.gc.cuny.edu/debates/text/99\n",
    "\n",
    "9. van Rossum, Guido, Barry Warsaw, and Nick Coghlan. “PEP 8 – Style Guide for Python Code.” July 5, 2001. Updated July 2013. https://www.python.org/dev/peps/pep-0008/\n",
    "\n",
    "10. “Ida M. Tarbell, 86, Dies in Bridgeport” The New York Times, January 7, 1944, 17. https://www.nytimes.com; “Nellie Bly, Journalist, Dies of Pneumonia” The New York Times, January 28, 1922, 11. https://www.nytimes.com; “W. E. B. DuBois Dies in Ghana; Negro Leader and Author, 95” The New York Times, August 28, 1963, 27. https://www.nytimes.com; Whitman, Alden. “Upton Sinclair, Author, Dead; Crusader for Social Justice, 90” The New York Times, November 26, 1968, 1, 34. https://www.nytimes.com; “Willa Cather Dies; Noted Novelist, 70” The New York Times, April 25, 1947, 21. https://www.nytimes.com\n",
    "\n",
    "11. Stray, Jonathan, and Julian Burgess. “A Full-text Visualization of the Iraq War Logs,” December 10, 2010 (Update April 2012). http://jonathanstray.com/a-full-text-visualization-of-the-iraq-war-logs\n",
    "\n",
    "12. Manning, C.D., P. Raghavan, and H. Schütze, Introduction to Information Retrieval. (Cambridge: Cambridge University Press, 2008): 118-120.\n",
    "\n",
    "13. Beckman, Milo. “These Are The Phrases Each GOP Candidate Repeats Most,” FiveThirtyEight, March 10, 2016. https://fivethirtyeight.com/features/these-are-the-phrases-each-gop-candidate-repeats-most/\n",
    "\n",
    "14. Bondi, Marina, and Mike Scott, eds. Keyness in Texts. (Philadelphia: John Benjamins, 2010).\n",
    "\n",
    "15. <p style='text-align: right;'>&#x202b;Tf-idf בדרך-כלל לא מומלצת לשימוש כשלב עיבוד מקדים כשמייצרים מודלי נושא. ראי את <a href=\"https://datascience.stackexchange.com/questions/21950/why-we-should-not-feed-lda-with-tfidf\">https://datascience.stackexchange.com/questions/21950/why-we-should-not-feed-lda-with-tfidf</a></p>\n",
    "\n",
    "16. Schmidt, Ben. “Words Alone: Dismantling Topic Models in the Humanities,” Journal of Digital Humanities. Vol. 2, No. 1 (2012): n.p. http://journalofdigitalhumanities.org/2-1/words-alone-by-benjamin-m-schmidt/\n",
    "\n",
    "17. Mihalcea, Rada, and Paul Tarau. “Textrank: Bringing order into text.” In Proceedings of the 2004 conference on empirical methods in natural language processing. 2004."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
